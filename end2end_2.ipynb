{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization query oriented\n",
    "\n",
    "__TO DO__ :\n",
    "- DocEmbedding with shifted LSTM\n",
    "- How to select partial summary during training ? Only part from the beginning or randomly chosen sentences ?\n",
    "- Generator of triplets \n",
    "- Metric for monitoring the test (See pyrouge) on a val set\n",
    "\n",
    " <hr style=\"border-color:#1d539d\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "import collections\n",
    "import copy\n",
    "import gensim\n",
    "import json\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paths to folders\n",
    "\n",
    "data_json = \"/home/ubuntu/summarization_query_oriented/data/json/patch_0/\"\n",
    "data_txt = \"/home/ubuntu/summarization_query_oriented/data/txt/\"\n",
    "model_folder = \"/home/ubuntu/summarization_query_oriented/models/\"\n",
    "nn_models_folder = \"/home/ubuntu/summarization_query_oriented/nn_models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# parameters of doc2vec\n",
    "dm = 0\n",
    "min_count = 5\n",
    "window = 10\n",
    "size = 400\n",
    "sample = 1e-4\n",
    "negative = 5\n",
    "workers = 4\n",
    "epoch = 20\n",
    "\n",
    "# Initialize the model ( IMPORTANT )\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec(dm=dm,min_count=min_count, window=window, size=size, sample=sample, negative=negative, workers=workers,iter = epoch)\n",
    "\n",
    "# load model\n",
    "model_name =\"dm_\"+str(dm)+\"_mc_\"+str(min_count)+\"_w_\"+str(window)+\"_size_\"+str(size)+\"_neg_\"+str(negative)+\"_ep_\"+str(epoch)\n",
    "d2v_model = d2v_model.load(model_folder+model_name+\".d2v\")\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 : fully connected model\n",
    "\n",
    "\n",
    "* __Architecture__ : Fully connected model\n",
    "\n",
    "\n",
    "* __Input__ : a vector that is the concatenation of [ query , partial summary, candidate ]\n",
    "    * *query* : here the subtitle of a wikipedia page\n",
    "    * *partial summary* : here a part (eventually void) of the summary attached to this subtitle\n",
    "    * *candidate* : a random sentence\n",
    "\n",
    "\n",
    "* __Output__ : a score describing how much the candidate sentence is completing the partial summary w.r.t the query \n",
    "\n",
    "\n",
    "* __Training mode__ : we sample triplet from wikipedia data to build the training set, we label 1 if the candidate sentence is a sentence of the correct subsection that is not in the partial summary (by building), we label 0 otherwise\n",
    "\n",
    "\n",
    "* __Testing mode__ : Given a document and a query. The partial summary is initialized as the query, then we choose the sentence of the document that is not in the partial summary with the highest score and delete it from the document. We repeat it until we reach the length limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing \n",
    "\n",
    "Here we build functions to perform end—to-end data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "non_selected_keys = [\"title\", \"external links\",\"further reading\",\"references\",\"see also\"]\n",
    "\n",
    "def has_at_least_one_relevant_key(file_as_dict):\n",
    "    \n",
    "    for key in file_as_dict.keys():\n",
    "        b = True\n",
    "        for unwanted_key in non_selected_keys:\n",
    "            if unwanted_key in key.lower() :\n",
    "                b = False    \n",
    "        if b :\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "def has_irrelevant_content(file_as_dict):\n",
    "    # remove articles with mathematics of chemics\n",
    "    for key in file_as_dict.keys():\n",
    "        if \"{\\\\\" in file_as_dict[key]:\n",
    "            return True        \n",
    "\n",
    "    # check that there is at least one interesting key\n",
    "    if not has_at_least_one_relevant_key(file_as_dict):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def relevant_articles(article_folder_path, min_size = 10000) : \n",
    "    \"\"\"\n",
    "    inputs :\n",
    "        - absolute path of the folder containing all the json articles\n",
    "        - min_size : retaining only file with at least size = min_size*10^-4 ko\n",
    "    output : \n",
    "        - article_names: nd array of the names of the relevant articles (absolute paths)\n",
    "        - article_weights : nd array normalized of the weights of each files\n",
    "    \"\"\"\n",
    "    all_names =  [f for f in listdir(article_folder_path)]\n",
    "    article_names = []\n",
    "    article_weights = []\n",
    "    for name in all_names:\n",
    "        article_weight = os.path.getsize(article_folder_path+name)\n",
    "        if article_weight > min_size:\n",
    "            # the size of the article meets the requirement\n",
    "            \n",
    "            with open(article_folder_path+name) as f :\n",
    "                file_as_dict = json.load(f) # get article as dict\n",
    "            \n",
    "            if not has_irrelevant_content(file_as_dict):\n",
    "                article_names.append(article_folder_path+name)\n",
    "                article_weights.append(article_weight)\n",
    "    \n",
    "    article_names = np.asarray(article_names)\n",
    "    article_weights = (np.asarray(article_weights) + 0.0) / np.sum(article_weights)\n",
    "        \n",
    "    return article_names, article_weights\n",
    "            \n",
    "def select_key(file_as_dict):\n",
    "    assert has_at_least_one_relevant_key(file_as_dict), \"the file has no relevant key\"\n",
    "\n",
    "    keys = file_as_dict.keys()\n",
    "    rand_idx = np.random.randint(0,len(keys))\n",
    "    selected_key = keys[rand_idx]\n",
    "    \n",
    "    if len(file_as_dict[selected_key].split(\".\"))<=2:\n",
    "        return select_key(file_as_dict)\n",
    "    \n",
    "    for unwanted_key in non_selected_keys :\n",
    "        if unwanted_key in selected_key.lower() :\n",
    "            return select_key(file_as_dict)\n",
    "        \n",
    "    return selected_key\n",
    "\n",
    "def create_triplets(d2v_model, article_names, article_weights, nb_triplets=20, triplets_per_file=5, neg_ratio=0.5, str_mode = False) :\n",
    "    \"\"\"\n",
    "    inputs :    \n",
    "        - d2v_model : paragraph vector model \n",
    "        - article_names : ndarray containing the names of the json files (absolute path !)\n",
    "        - article_weights: ndarray normalized of the weight of each files \n",
    "        - nb_triplets : nb of triplets to generate\n",
    "        - triplets_per_file : number of triplet built for each selected file\n",
    "        - neg_ratio : ratio of positives / negative examples. Negative examples are taken inside the article !\n",
    "        \n",
    "    output : \n",
    "        - triplets : nd_array of triplets of shape (nb_triplets+ , embed_dim)\n",
    "        - labels : nd_array of labels of shape (nb_triplets+ ,)\n",
    "\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    labels = []\n",
    "    \n",
    "    assert nb_triplets>=triplets_per_file, \"you should have nb_triplets > triplets_per_file\"\n",
    "    \n",
    "    # nb of pos / neg triplets per file\n",
    "    neg_per_file = np.floor(triplets_per_file*neg_ratio) #number of negative triplets to generate given(query + partial summary)\n",
    "    assert neg_per_file >= 1, \"you have to increase your neg_ratio\"\n",
    "    \n",
    "    nb_files = nb_triplets / triplets_per_file\n",
    "    selected_files_array = np.random.choice(article_names, size=nb_files, p=article_weights, replace = False)\n",
    "    \n",
    "    for full_name in selected_files_array :\n",
    "        with open(full_name) as f :\n",
    "            file_as_dict = json.load(f)\n",
    "        \n",
    "        counter = 0\n",
    "        while counter < triplets_per_file :\n",
    "            \n",
    "            # select a key for positive examples\n",
    "            key_pos = select_key(file_as_dict)\n",
    "            \n",
    "            triplet = build_triplet(d2v_model, file_as_dict, key_pos, positive = True, str_mode = str_mode)\n",
    "            label = 1\n",
    "            \n",
    "            triplets.append(triplet)\n",
    "            labels.append(label)\n",
    "            counter += 1 \n",
    "            \n",
    "            if neg_ratio < 1 : \n",
    "                \n",
    "                if np.random.rand() < neg_ratio :\n",
    "                    \n",
    "                    triplet = build_triplet(d2v_model, file_as_dict, key_pos, positive = False, str_mode = str_mode)\n",
    "                    label = 0\n",
    "                    \n",
    "                    triplets.append(triplet)\n",
    "                    labels.append(label)\n",
    "                    counter += 1 \n",
    "\n",
    "            else :\n",
    "                \n",
    "                for n in range(int(np.floor(neg_ratio))):\n",
    "                    \n",
    "                    triplet = build_triplet(d2v_model, file_as_dict, key_pos, positive = False, str_mode = str_mode)\n",
    "                    label = 0\n",
    "                    \n",
    "                    triplets.append(triplet)\n",
    "                    labels.append(label)\n",
    "                    counter += 1 \n",
    "\n",
    "            \n",
    "    triplets = np.asarray(triplets)[:nb_triplets]\n",
    "    labels = np.asarray(labels)[:nb_triplets]\n",
    "    \n",
    "    return triplets, labels\n",
    "\n",
    "def build_triplet(d2v_model, file_as_dict, key_pos, positive = True, str_mode = False):\n",
    "\n",
    "    query_str = key_pos\n",
    "    query_prep = gensim.utils.simple_preprocess(query_str, deacc=True)\n",
    "    query_vector = d2v_model.infer_vector(query_prep)\n",
    "    \n",
    "    summary_str = file_as_dict[key_pos]\n",
    "    sentences = summary_str.split(\".\")\n",
    "    \n",
    "    partial_summary = []\n",
    "    candidates = []\n",
    "    \n",
    "    size_partial_summary = np.random.rand()\n",
    "    \n",
    "    for sentence in sentences: \n",
    "        if np.random.rand() < size_partial_summary :\n",
    "            partial_summary.append(sentence)\n",
    "        else :\n",
    "            candidates.append(sentence)\n",
    "    \n",
    "    candidate = \"\"\n",
    "    counter_candidate = 0\n",
    "    while (candidate == \"\" or partial_summary == \"\") and counter_candidate < 10:\n",
    "        counter_candidate += 1\n",
    "        \n",
    "        if positive : \n",
    "            if len(candidates) > 0:\n",
    "                random_candidate_index = np.random.randint(0,len(candidates))\n",
    "                candidate = candidates[random_candidate_index]\n",
    "            else :\n",
    "                random_candidate_index = np.random.randint(0,len(partial_summary))\n",
    "                candidate = partial_summary[random_candidate_index]\n",
    "                partial_summary[random_candidate_index] = \"\"\n",
    "\n",
    "\n",
    "            candidate_prep = gensim.utils.simple_preprocess(candidate, deacc=True)\n",
    "            candidate_vector = d2v_model.infer_vector(candidate_prep)\n",
    "\n",
    "        else :\n",
    "\n",
    "            key_neg = select_key(file_as_dict)\n",
    "            counter = 0\n",
    "\n",
    "            while key_neg == key_pos and counter<10 : # the counter is for the preproduction code \n",
    "                counter += 1\n",
    "                key_neg = select_key(file_as_dict)\n",
    "\n",
    "            summary_str = file_as_dict[key_neg]\n",
    "\n",
    "            sentences = summary_str.split('.')\n",
    "            random_candidate_index = np.random.randint(0,len(sentences))\n",
    "            candidate = sentences[random_candidate_index]\n",
    "            candidate_prep = gensim.utils.simple_preprocess(candidate, deacc=True)\n",
    "            candidate_vector = d2v_model.infer_vector(candidate_prep)\n",
    "        \n",
    "        partial_summary_str = \"\".join(partial_summary)\n",
    "        partial_summary_prep = gensim.utils.simple_preprocess(partial_summary_str, deacc=True)\n",
    "        partial_summary_vector = d2v_model.infer_vector(partial_summary_prep)\n",
    "    \n",
    "    if str_mode :\n",
    "        return query_str, partial_summary_str, candidate\n",
    "    else :\n",
    "        return np.hstack( [query_vector, partial_summary_vector, candidate_vector] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data processing\n",
    "article_names, article_weights = relevant_articles(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZcwhYGaWsf8PYkjHymUFcB0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd964ddad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(article_weights*10000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ILLUSTRATION BLOCK : Here you can play with the triplet maker and see what gives triplet labelisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Internet Relay Chat History EFnet\n",
      "\n",
      "partial summary : In August 1990 the first major disagreement took place in the IRC world The \"A-net\" (Anarchy net) included a server named erisberkeley In wumpus' words again: \"Eris refused to remove that line, so I formed EFnet It wasn't much of a fight; I got all the hubs to join, and almost everyone else got carried along\" A-net was formed with the eris servers, EFnet was formed with the non-eris servers History showed most servers and users went with EFnet Once ANet disbanded, the name EFnet became meaningless, and once again it was the one and only IRC network\n",
      "It is around that time that IRC was used to report on the 1991 Soviet coup d'état attempt throughout a media blackout It was previously used in a similar fashion during the Gulf War Chat logs of these and other events are kept in the ibiblio archive\n",
      "\n",
      "candidate : edu\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Internet Relay Chat History EFnet\n",
      "\n",
      "partial summary : In August 1990 the first major disagreement took place in the IRC worldberkeley As Greg \"wumpus\" Lindahl explains: \"it had a wildcard server line, so people were hooking up servers and nick-colliding everyone\" The \"Eris Free Network\", EFnet, made the eris machine the first to be Q-lined (Q for quarantine) from IRC In wumpus' words again: \"Eris refused to remove that line, so I formed EFnet It wasn't much of a fight; I got all the hubs to join, and almost everyone else got carried along\n",
      "\n",
      "candidate :  IRC is mainly designed for group communication in discussion forums, called channels, but also allows one-on-one communication via private messages as well as chat and data transfer, including file sharing\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Internet Relay Chat History The IRCnet fork or the Great Split\n",
      "\n",
      "partial summary : \n",
      "\n",
      "candidate :  Most notably, the \"european\" (most of those servers were in Europe) side that later named itself IRCnet argued for nick and channel delays where the EFnet side argued for timestamps\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Internet Relay Chat History The IRCnet fork or the Great Split\n",
      "\n",
      "partial summary : \n",
      "Most (not all) of the IRCnet servers were in Europe, while most of the EFnet server were in the US This event is also known as \"The Great Split\" in many IRC societies In the autumn year 2000, EFnet had some 50,000 users and IRCnet 70,000\n",
      "\n",
      "candidate : \n",
      "Some IRC servers support SSL/TLS connections for security purposes\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Internet Relay Chat Technical information Modes\n",
      "\n",
      "partial summary : Users and channels may have modes that are represented by single case-sensitive letters and are set using the MODE command User modes and channel modes are separate and can use the same letter to mean different things (eg user mode \"i\" is invisible mode while channel mode \"i\" is invite only) Modes are usually set and unset using the mode command that takes a target (user or channel), a set of modes to set (+) or unset (-) and any parameters the modes need\n",
      "Some but not all channel modes take parameters and some channel modes apply to a user on a channel or add or remove a mask (e a ban mask) from a list associated with the channel rather than applying to the channel as a whole Modes that apply to users on a channel have an associated symbol that is used to represent the mode in names replies (sent to clients on first joining a channel and use of the names command) and in many clients also used to represent it in the client's displayed list of users in a channel or to display an own indicator for a user's modes In early implementations of IRC this had to be hard-coded in the client but there is now a de facto standard extension to the protocol called ISUPPORT that sends this information to the client at connect time using numeric 005\n",
      "There is a small design fault in IRC regarding modes that apply to users on channels: the names message used to establish initial channel state can only send one such mode per user on the channel, but multiple such modes can be set on a single user For example, if a user holds both operator status (+o) and voice status (+v) on a channel, a new client will be unable to see the mode with less priority (i Workarounds for this are possible on both the client and server side but none are widely implemented\n",
      "\n",
      "candidate : \n",
      "In order to correctly parse incoming mode messages and track channel state the client must know which mode is of which type and for the modes that apply to a user on a channel which symbol goes with which letter\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Internet Relay Chat Technical information Modes\n",
      "\n",
      "partial summary : Users and channels may have modes that are represented by single case-sensitive letters and are set using the MODE command User modes and channel modes are separate and can use the same letter to mean different things (eg user mode \"i\" is invisible mode while channel mode \"i\" is invite only) Modes are usually set and unset using the mode command that takes a target (user or channel), a set of modes to set (+) or unset (-) and any parameters the modes need\n",
      "Some but not all channel modes take parameters and some channel modes apply to a user on a channel or add or remove a mask (eg a ban mask) from a list associated with the channel rather than applying to the channel as a whole Modes that apply to users on a channel have an associated symbol that is used to represent the mode in names replies (sent to clients on first joining a channel and use of the names command) and in many clients also used to represent it in the client's displayed list of users in a channel or to display an own indicator for a user's modes\n",
      "In order to correctly parse incoming mode messages and track channel state the client must know which mode is of which type and for the modes that apply to a user on a channel which symbol goes with which letter In early implementations of IRC this had to be hard-coded in the client but there is now a de facto standard extension to the protocol called ISUPPORT that sends this information to the client at connect time using numeric 005\n",
      "There is a small design fault in IRC regarding modes that apply to users on channels: the names message used to establish initial channel state can only send one such mode per user on the channel, but multiple such modes can be set on a single user For example, if a user holds both operator status (+o) and voice status (+v) on a channel, a new client will be unable to see the mode with less priority (ie voice)\n",
      "\n",
      "candidate : \n",
      "Technically, IRC provides no file transfer mechanisms itself; file sharing is implemented by IRC clients, typically using the Direct Client-to-Client (DCC) protocol, in which file transfers are negotiated through the exchange of private messages between clients\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Internet Relay Chat Technical information Channel Operators\n",
      "\n",
      "partial summary : A Channel Operator is a client on an IRC channel that manages the channel On most networks, an operator can:\n",
      "Kick a user\n",
      "Ban a user\n",
      "Give another user IRC Channel Operator Status or IRC Channel Voice Status\n",
      "Change the IRC Channel topic while channel mode +t is set\n",
      "Change the IRC Channel Mode locks\n",
      "\n",
      "candidate :  IRC Channel Operators can be easily seen by the \"@\" symbol prefixed to their name, or a Latin letter \"+o\"/\"o\"\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Internet Relay Chat Technical information Channel Operators\n",
      "\n",
      "partial summary : A Channel Operator is a client on an IRC channel that manages the channel IRC Channel Operators can be easily seen by the \"@\" symbol prefixed to their name, or a Latin letter \"+o\"/\"o\"\n",
      "Change the IRC Channel topic while channel mode +t is set\n",
      "Change the IRC Channel Mode locks\n",
      "\n",
      "candidate :  If a user could join on a \"split\" server, where a channel that existed on the other side of the network was empty, and gain operator status, they would become a channel operator of the \"combined\" channel after the netsplit ended; if a user took a nickname that existed on the other side of the network, the server would kill both users when rejoining (i\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Systems theory in anthropology Main concepts in systems theory Non-representational and non-referential\n",
      "\n",
      "partial summary : ” The tracing rather than projecting mental images bring in sight material reality that has been obscured under the universalizing concepts\n",
      "\n",
      "candidate :  What it means that instead of imposing mental concepts, which reduce complexity of a materiality by limiting the variations or malleability, onto the objects; one should trace the network of things\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Systems theory in anthropology Main concepts in systems theory Non-representational and non-referential\n",
      "\n",
      "partial summary : One of the central elements of the systems theory is to move away from the representational system to the non-representation of things According to Gregory Bateson, “ethos, eidos, sociology, economics, cultural structure, social structure, and all the rest of these words refer only to scientists’ ways of putting the jigsaw puzzle\n",
      "\n",
      "candidate : Ludwig Bertalanaffy describes two types of systems: open system and closed system\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Systems theory in anthropology System theory: Gregory Bateson Posthumanist turn and ethnographic writing\n",
      "\n",
      "partial summary : In anthropology, the task of representing a native point of view has been a challenging one The idea behind the ethnographic writing is to understand a complexity of an everyday life of the people without undermining or reducing the native account Historically, as mentioned above, ethnographers insert raw data, collected in the fieldwork, into the writing \"machine\" The output is usually the neat categories of ethnicity, identity, classes, kinship, genealogy, religion, culture, violence, and numerous other Anthropologists are now thinking of experimenting with new style of writing\n",
      "\n",
      "candidate :  For instance, writing with natives or multiple authorship\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Systems theory in anthropology System theory: Gregory Bateson Posthumanist turn and ethnographic writing\n",
      "\n",
      "partial summary :  Historically, as mentioned above, ethnographers insert raw data, collected in the fieldwork, into the writing \"machine\" The output is usually the neat categories of ethnicity, identity, classes, kinship, genealogy, religion, culture, violence, and numerous other Anthropologists are now thinking of experimenting with new style of writing For instance, writing with natives or multiple authorship\n",
      "\n",
      "candidate :  An open system is defined as a “system in exchange of matter with its environment, presenting import and export, building-up and breaking-down of its material components\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Systems theory in anthropology Main concepts in systems theory Non-Cartesian\n",
      "\n",
      "partial summary : \n",
      "\n",
      "candidate : Since the European Enlightenment, the Western philosophy has placed the individual, as an indispensable category, at the center of the universe\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Systems theory in anthropology Main concepts in systems theory Non-Cartesian\n",
      "\n",
      "partial summary : Since the European Enlightenment, the Western philosophy has placed the individual, as an indispensable category, at the center of the universe René Descartes' famous aphorism, 'I think therefore I am' proves that a person is a rational subject whose feature of thinking brings the human into existence The Cartesian subject, therefore, is a scientific individual who imposes mental concepts on things in order to control the nature or simply what exists outside his mind One of the biggest challenges for system theory is thus to displace or de-center the Cartesian subject as a center of a universe and as a rational being The humans are not thinking Cartesian subject but they dwell alongside nature\n",
      "\n",
      "candidate : ” For example, living organism\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Systems theory in anthropology System theory: Gregory Bateson Influences on poststructuralism\n",
      "\n",
      "partial summary : Bateson's work influenced major poststructuralist scholars especially Gilles Deleuze and Félix Guattari” Bateson pioneered an interdisciplinary approach in anthropology He coined the term “ecology of mind” to demonstrate that what \"goes on in one's head and in one's behavior\" is interlocked and constitutes a network Guattari wrote:\n",
      "\n",
      "Gregory Bateson has clearly shown that what he calls the “ecology of ideas” cannot be contained within the domain of the psychology of the individual, but organizes itself into systems or “minds”, the boundaries of which no longer coincide with the participant individuals\n",
      "\n",
      "candidate :  In fact, the very word 'plateau' in Deleuze and Guattari's magnum opus, A Thousand Plateaus, came from Bateson's work on Balinese culture\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Systems theory in anthropology System theory: Gregory Bateson Influences on poststructuralism\n",
      "\n",
      "partial summary : \n",
      "\n",
      "candidate :  In fact, boundaries must be seen as “porous and permeable,” and “pluralized\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Debate History\n",
      "\n",
      "partial summary : \n",
      "\n",
      "candidate : Although debating in various forms has a long history, and can be traced back to the philosophical and political debates of Ancient Greece, such as Athenian democracy, modern forms of debating and the establishment of debating societies occurred during the Age of Enlightenment in the 18th century\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Debate History\n",
      "\n",
      "partial summary : \n",
      "\n",
      "candidate :  Crossballs: The Debate Show is a Comedy Central television show which poked fun at cable news networks' political debate shows\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Debate Other forms of debate Debate shows\n",
      "\n",
      "partial summary :  The winner is chosen by audience applause at the end of the debate\n",
      "\n",
      "candidate : \n",
      "The Debaters is a Canadian radio comedy show in which two debaters (usually stand up comedians) debate topics, which are deliberately comedic (such as \"backseat drivers are helpful\", \"gravity is our friend\" and \"cats are smarter than dogs\"\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Debate Other forms of debate Debate shows\n",
      "\n",
      "partial summary :  The winner is chosen by audience applause at the end of the debate\n",
      "\n",
      "candidate : The first student debating society was the St Andrews Debating Society, formed in 1794 as the Literary Society\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Debate History\n",
      "\n",
      "partial summary : Although debating in various forms has a long history, and can be traced back to the philosophical and political debates of Ancient Greece, such as Athenian democracy, modern forms of debating and the establishment of debating societies occurred during the Age of Enlightenment in the 18th century\n",
      "\n",
      "candidate : \n",
      "Debating teams are often helpful to high school students in teaching the writing process, as well as in teaching rhetoric\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Debate History\n",
      "\n",
      "partial summary : Although debating in various forms has a long history, and can be traced back to the philosophical and political debates of Ancient Greece, such as Athenian democracy, modern forms of debating and the establishment of debating societies occurred during the Age of Enlightenment in the 18th century\n",
      "Debating teams are often helpful to high school students in teaching the writing process, as well as in teaching rhetoric\n",
      "\n",
      "candidate : \n",
      "The Cambridge Society served as a model for the subsequent foundation of similar societies at several other prominent universities, including the Oxford Union and the Yale Political Union\n",
      "--------------------------------------------------\n",
      "label =  1\n",
      "\n",
      "query : Debate History\n",
      "\n",
      "partial summary : \n",
      "\n",
      "candidate : Although debating in various forms has a long history, and can be traced back to the philosophical and political debates of Ancient Greece, such as Athenian democracy, modern forms of debating and the establishment of debating societies occurred during the Age of Enlightenment in the 18th century\n",
      "--------------------------------------------------\n",
      "label =  0\n",
      "\n",
      "query : Debate History\n",
      "\n",
      "partial summary : Although debating in various forms has a long history, and can be traced back to the philosophical and political debates of Ancient Greece, such as Athenian democracy, modern forms of debating and the establishment of debating societies occurred during the Age of Enlightenment in the 18th century\n",
      "\n",
      "candidate :  The origins of these societies are not certain in many cases however, by the mid-18th century, London fostered an active debating society culture\n"
     ]
    }
   ],
   "source": [
    "triplets, labels = create_triplets(d2v_model, article_names, article_weights, nb_triplets=25, triplets_per_file=8, neg_ratio=1, str_mode = True)\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    print 50*'-'\n",
    "    print \"label = \", labels[i]\n",
    "    print \"\\nquery :\", triplets[i][0]\n",
    "    print \"\\npartial summary :\", triplets[i][1]\n",
    "    print \"\\ncandidate :\", triplets[i][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "fc_model_name = nn_models_folder + time.strftime(\"%Y_%m_%d_\") +'_fc_model.h5' # replace it with hour of training\n",
    "\n",
    "fc_model = Sequential()\n",
    "\n",
    "fc_model.add(Dense(120, input_dim=1200))\n",
    "fc_model.add(Activation('sigmoid'))\n",
    "fc_model.add(Dropout(0.5))\n",
    "\n",
    "fc_model.add(Dense(12))\n",
    "fc_model.add(Activation('sigmoid'))\n",
    "fc_model.add(Dropout(0.5))\n",
    "\n",
    "fc_model.add(Dense(1))\n",
    "fc_model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "fc_model.compile(loss=\"binary_crossentropy\", optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (we use training per batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "for i in range(200):\n",
    "    if i%10 == 0 : \n",
    "        print(i)\n",
    "    triplets, labels = create_triplets(d2v_model, article_names, article_weights, nb_triplets=batch_size, triplets_per_file=16, neg_ratio=1, str_mode = False)\n",
    "    fc_model.train_on_batch(triplets, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "triplets_tests , labels_tests = create_triplets(d2v_model, article_names, article_weights, nb_triplets=128, triplets_per_file=16, neg_ratio=1, str_mode = False)\n",
    "labels_predicted = fc_model.predict(triplets_tests , batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s\n",
      "0.693373680115\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = fc_model.evaluate(triplets_tests, labels_tests, batch_size=batch_size)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.py:136: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "fc_model.save(fc_model_name)  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "del fc_model  # deletes the existing model\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "fc_model = load_model(fc_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_model = load_model(fc_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General info on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 120)           144120      dense_input_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 120)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 120)           0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 12)            1452        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 12)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 12)            0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             13          dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 1)             0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 145585\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "[{'class_name': 'Dense', 'config': {'W_constraint': None, 'b_constraint': None, 'name': u'dense_1', 'output_dim': 120, 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'input_dtype': u'float32', 'input_dim': 1200, 'b_regularizer': None, 'W_regularizer': None, 'activation': 'linear', 'batch_input_shape': (None, 1200)}}, {'class_name': 'Activation', 'config': {'activation': 'sigmoid', 'trainable': True, 'name': u'activation_1'}}, {'class_name': 'Dropout', 'config': {'p': 0.5, 'trainable': True, 'name': u'dropout_1'}}, {'class_name': 'Dense', 'config': {'W_constraint': None, 'b_constraint': None, 'name': u'dense_2', 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'input_dim': None, 'b_regularizer': None, 'W_regularizer': None, 'activation': 'linear', 'output_dim': 12}}, {'class_name': 'Activation', 'config': {'activation': 'sigmoid', 'trainable': True, 'name': u'activation_2'}}, {'class_name': 'Dropout', 'config': {'p': 0.5, 'trainable': True, 'name': u'dropout_2'}}, {'class_name': 'Dense', 'config': {'W_constraint': None, 'b_constraint': None, 'name': u'dense_3', 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'input_dim': None, 'b_regularizer': None, 'W_regularizer': None, 'activation': 'linear', 'output_dim': 1}}, {'class_name': 'Activation', 'config': {'activation': 'sigmoid', 'trainable': True, 'name': u'activation_3'}}]\n"
     ]
    }
   ],
   "source": [
    "print(fc_model.summary())\n",
    "print(fc_model.get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize(text, query, d2v_model, nn_model, limit = 2000):\n",
    "\n",
    "    query_prep = gensim.utils.simple_preprocess(query, deacc=True)\n",
    "    query_vector = d2v_model.infer_vector(query_prep)\n",
    "    \n",
    "    summary  = \"\"\n",
    "    summary_vector = d2v_model.infer_vector([\"\"])\n",
    "    summary_idx = []\n",
    "    \n",
    "    sentences = text.split('.')\n",
    "    sentences = np.asarray(sentences)\n",
    "    \n",
    "    remaining_sentences = copy.copy(sentences)\n",
    "    \n",
    "    size = 0\n",
    "    counter = 0\n",
    "    while size < limit and len(remaining_sentences)>0 :\n",
    "        counter = counter+1\n",
    "\n",
    "        for sentence in remaining_sentences :\n",
    "            \n",
    "            scores = []\n",
    "            sentence_prep = gensim.utils.simple_preprocess(sentence, deacc=True)\n",
    "            sentence_vector = d2v_model.infer_vector(sentence_prep)\n",
    "\n",
    "            nn_input = np.hstack([query_vector, summary_vector, sentence_vector])\n",
    "            nn_input = np.asarray([nn_input]) # weird but it is important to do it\n",
    "            score = nn_model.predict(nn_input) \n",
    "            scores.append(score)\n",
    "            \n",
    "        max_idx_rem = int(np.argmax(scores))\n",
    "        idx_selected_sentence = np.arange(len(sentences))[sentences == remaining_sentences[max_idx_rem]]\n",
    "        idx_selected_sentence = int(idx_selected_sentence[0])\n",
    "        size += len(remaining_sentences[max_idx_rem])\n",
    "        remaining_sentences = list(remaining_sentences)\n",
    "        del remaining_sentences[max_idx_rem]\n",
    "        bisect.insort_left(summary_idx,idx_selected_sentence)\n",
    "\n",
    "        summary  = \"\"\n",
    "\n",
    "        for idx in summary_idx:\n",
    "            summary = summary + \" \" + sentences[idx]\n",
    "\n",
    "        summary_prep = gensim.utils.simple_preprocess(summary, deacc=True)\n",
    "        summary_vector = d2v_model.infer_vector(summary_prep)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "query History of Israel Babylonian rule (586–538 BCE)\n",
      "**************************************************\n",
      "real summary\n",
      "\n",
      "In 586 BCE King Nebuchadnezzar II of Babylon conquered Judah. According to the Hebrew Bible, he destroyed Solomon's Temple and exiled the Jews to Babylon. The defeat was also recorded by the Babylonians (see the Babylonian Chronicles). Babylonian and Biblical sources suggest that the Judean king, Jehoiachin, switched allegiances between the Egyptians and the Babylonians and that invasion was a punishment for allying with Babylon's principal rival, Egypt. The exiled Jews may have been restricted to the elite.\n",
      "Jehoiachin was eventually released by the Babylonians (see Jehoiachin's Rations Tablets) and according to both the Bible and the Talmud, the Judean royal family (the Davidic line) continued as head of the exile in Babylon (the Exilarch).\n",
      "**************************************************\n",
      "nn summary\n",
      "\n",
      "  The British Empire was severely weakened by the war  In the Middle East, the war had made Britain conscious of its dependence on Arab oil  British firms controlled Iraqi oil and Britain ruled Kuwait, Bahrain and the Emirates  Shortly after VE Day, the Labour Party won the general election in Britain  Although Labour Party conferences had for years called for the establishment of a Jewish state in Palestine, the Labour government now decided to maintain the 1939 White Paper policies \n",
      "\n",
      "Illegal migration (Aliyah Bet) became the main form of Jewish entry into Palestine  Across Europe Bricha (\"flight\"), an organization of former partisans and ghetto fighters, smuggled Holocaust survivors from Eastern Europe to Mediterranean ports, where small boats tried to breach the British blockade of Palestine\n"
     ]
    }
   ],
   "source": [
    "wikipedia_title = \"History of Israel\"\n",
    "with open(data_json+wikipedia_title+\".json\", 'r') as f:\n",
    "    wiki_as_json = json.load(f)\n",
    "\n",
    "text = \"\"\n",
    "for key in wiki_as_json.keys():\n",
    "    if key not in non_selected_keys:\n",
    "        text += \" \" + wiki_as_json[key]\n",
    "        \n",
    "random_idx = np.random.randint(0,len(wiki_as_json.keys()))\n",
    "query = wiki_as_json.keys()[random_idx]\n",
    "summary_true = wiki_as_json[query]\n",
    "limit_size = len(wiki_as_json[query])\n",
    "\n",
    "print 50*\"*\"\n",
    "print 'query', query\n",
    "print 50*\"*\"\n",
    "print \"real summary\\n\\n\", summary_true\n",
    "print 50*\"*\"\n",
    "print \"nn summary\\n\\n\", summarize(text,query,d2v_model, fc_model, limit = limit_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 : LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "list1 = [1,2,3,4]\n",
    "list2 = copy.copy(list1)\n",
    "del list1[0]\n",
    "print (list1)\n",
    "print (list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0]\n",
    "a.sort()\n",
    "a\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
