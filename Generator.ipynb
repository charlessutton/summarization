{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glove import Glove\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_file = \"/home/ubuntu/summarization_query_oriented/data/wikipedia/txt/td_qfs_rank_1_all.txt\"\n",
    "with open(txt_file, 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "word_embedder_folder = \"/home/ubuntu/summarization_query_oriented/nn_models/word_vectorization_models/glove/\"\n",
    "word_embedder = \"rank1_alltxt_size_400_epoch_30.glove\"\n",
    "\n",
    "glove = Glove.load(word_embedder_folder+word_embedder) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sentences = text.decode(\"utf-8\").split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'bauxite', u'pneumoconiosis', u'also', u'known', u'as', u'shaver', u'disease', u'corundum', u'smelter', u'lung', u'bauxite', u'lung', u'or', u'bauxite', u'smelters', u'disease', u'is', u'progressive', u'form', u'of', u'pneumoconiosis', u'caused', u'by', u'exposure', u'to', u'bauxite', u'fumes', u'which', u'contain', u'aluminium', u'and', u'silica', u'particulates']\n",
      "[u'it', u'is', u'typically', u'seen', u'in', u'workers', u'involved', u'in', u'the', u'smelting', u'of', u'bauxite', u'to', u'produce', u'corundum']\n"
     ]
    }
   ],
   "source": [
    "for sentence in all_sentences[:2]:\n",
    "    print gensim.utils.simple_preprocess(sentence, deacc=False, min_len=2, max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_vector(word ,corpus):\n",
    "    \"\"\"\n",
    "    given a corpus of (key,value) = (word,index) , this function return a one hot vector corresponding the input word\n",
    "    \"\"\"\n",
    "    size = len(corpus.values())\n",
    "    y = np.zeros(size)\n",
    "    y[corpus[word]] = 1.0\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bidirectional_batch_generator(text, glove_model):\n",
    "    \"\"\"\n",
    "    Generator of bidirectional batchs to train on a regular LSTM model\n",
    "    It yields :\n",
    "    - X a batch representing a single sentence, therefore the size of the batch vary between each batch\n",
    "    - y a batch of one hot vectors representing the next word to find\n",
    "    \n",
    "    \"\"\"\n",
    "    corpus = glove_model.dictionary\n",
    "    corpus_size = len(corpus.keys())\n",
    "    all_sentences = text.decode(\"utf-8\").split(\".\")\n",
    "    for sentence in all_sentences :\n",
    "        \n",
    "        word_list = gensim.utils.simple_preprocess(sentence, deacc=False, min_len=2, max_len=15)\n",
    "        corpus[u'SENTENCE_START'] = corpus_size\n",
    "        corpus[u'SENTENCE_END'] = corpus_size + 1\n",
    "        \n",
    "        word_list.insert(0,u'SENTENCE_START')\n",
    "        word_list.append(u'SENTENCE_END')\n",
    "        \n",
    "        for direction in [True,False] : \n",
    "            X = []\n",
    "            y = []\n",
    "\n",
    "            if not direction : word_list = word_list[::-1]\n",
    "\n",
    "            for i in range(len(word_list)-1):\n",
    "                if corpus[word_list[i]] <corpus_size:\n",
    "                    X.append(glove_model.word_vectors[corpus[word_list[i]]])\n",
    "                else :\n",
    "                    # case sentence_start sentence_end\n",
    "                    X.append(np.zeros(glove.no_components)) \n",
    "\n",
    "                y.append(one_hot_vector(word_list[i+1],corpus))    \n",
    "                \n",
    "            X = np.asarray(X)\n",
    "            y = np.asarray(y)\n",
    "            yield X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generat = bidirectional_batch_generator(text, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = generat.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 400)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bauxite\n",
      "pneumoconiosis\n",
      "also\n",
      "known\n",
      "as\n",
      "shaver\n",
      "disease\n",
      "corundum\n",
      "smelter\n",
      "lung\n",
      "bauxite\n",
      "lung\n",
      "or\n",
      "bauxite\n",
      "smelters\n",
      "disease\n",
      "is\n",
      "progressive\n",
      "form\n",
      "of\n",
      "pneumoconiosis\n",
      "caused\n",
      "by\n",
      "exposure\n",
      "to\n",
      "bauxite\n",
      "fumes\n",
      "which\n",
      "contain\n",
      "aluminium\n",
      "and\n",
      "silica\n",
      "particulates\n",
      "SENTENCE_END\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y)):\n",
    "    word_idx = np.arange(len(glove.dictionary.keys())) [y[i,:]==1.0]\n",
    "    for key in glove.dictionary.keys():\n",
    "        if glove.dictionary[key] == word_idx :\n",
    "            print key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(glove.word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.no_components"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
