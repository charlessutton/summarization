{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "import collections\n",
    "import copy\n",
    "import gensim\n",
    "import json\n",
    "import keras\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import pyrouge\n",
    "from pyrouge import Rouge155\n",
    "import random\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lang_model_folder = \"/home/ubuntu/summarization_query_oriented/nn_models/language_models/d2v/\"\n",
    "nn_summarizers_folder = \"/home/ubuntu/summarization_query_oriented/nn_models/nn_summarizer/\"\n",
    "model_dir = \"/home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_model\"\n",
    "current_time_str = time.strftime(\"%Y_%m_%d_%H_%M_\")\n",
    "system_folder = \"/home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/\" + current_time_str + \"test/\"\n",
    "os.mkdir(system_folder)\n",
    "tdqfs_folder = \"/home/ubuntu/summarization_query_oriented/data/TD-QFS/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "themes = [\"alz\",\"asthma\",\"cancer\",\"obese\"]\n",
    "non_selected_keys = [\"title\", \"external links\",\"further reading\",\"references\",\"see also\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def has_at_least_one_relevant_key(file_as_dict):\n",
    "    \n",
    "    for key in file_as_dict.keys():\n",
    "        b = True\n",
    "        for unwanted_key in non_selected_keys:\n",
    "            if unwanted_key in key.lower() :\n",
    "                b = False    \n",
    "        if b :\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "def has_irrelevant_content(file_as_dict):\n",
    "    # remove articles with mathematics of chemics\n",
    "    for key in file_as_dict.keys():\n",
    "        if \"{\\\\\" in file_as_dict[key]:\n",
    "            return True        \n",
    "\n",
    "    # check that there is at least one interesting key\n",
    "    if not has_at_least_one_relevant_key(file_as_dict):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def relevant_articles(article_folder_path, min_size = 10000) : \n",
    "    \"\"\"\n",
    "    inputs :\n",
    "        - absolute path of the folder containing all the json articles\n",
    "        - min_size : retaining only file with at least size = min_size*10^-4 ko\n",
    "    output : \n",
    "        - article_names: nd array of the names of the relevant articles (absolute paths)\n",
    "        - article_weights : nd array normalized of the weights of each files\n",
    "    \"\"\"\n",
    "    all_names =  [f for f in listdir(article_folder_path)]\n",
    "    article_names = []\n",
    "    article_weights = []\n",
    "    for name in all_names:\n",
    "        article_weight = os.path.getsize(article_folder_path+name)\n",
    "        if article_weight > min_size:\n",
    "            # the size of the article meets the requirement\n",
    "            \n",
    "            with open(article_folder_path+name) as f :\n",
    "                file_as_dict = json.load(f) # get article as dict\n",
    "            \n",
    "            if not has_irrelevant_content(file_as_dict):\n",
    "                article_names.append(article_folder_path+name)\n",
    "                article_weights.append(article_weight)\n",
    "    \n",
    "    article_names = np.asarray(article_names)\n",
    "    article_weights = (np.asarray(article_weights) + 0.0) / np.sum(article_weights)\n",
    "        \n",
    "    return article_names, article_weights\n",
    "            \n",
    "def select_key(file_as_dict, patience = 10):\n",
    "    if patience > 0 :\n",
    "        assert has_at_least_one_relevant_key(file_as_dict), \"the file has no relevant key\"\n",
    "\n",
    "        keys = file_as_dict.keys()\n",
    "        rand_idx = np.random.randint(0,len(keys))\n",
    "        selected_key = keys[rand_idx]\n",
    "\n",
    "        if len(file_as_dict[selected_key].split(\".\"))<=2:\n",
    "            return select_key(file_as_dict, patience = patience - 1)\n",
    "\n",
    "        for unwanted_key in non_selected_keys :\n",
    "            if unwanted_key in selected_key.lower() :\n",
    "                return select_key(file_as_dict, patience = patience - 1)\n",
    "\n",
    "        return selected_key\n",
    "    else : \n",
    "        keys = file_as_dict.keys()\n",
    "        rand_idx = np.random.randint(0,len(keys))\n",
    "        selected_key = keys[rand_idx]\n",
    "        return selected_key\n",
    "\n",
    "def create_triplets(d2v_model, article_names, article_weights, nb_triplets=20, triplets_per_file=5, neg_ratio=0.5, str_mode = False) :\n",
    "    \"\"\"\n",
    "    inputs :    \n",
    "        - d2v_model : paragraph vector model \n",
    "        - article_names : ndarray containing the names of the json files (absolute path !)\n",
    "        - article_weights: ndarray normalized of the weight of each files \n",
    "        - nb_triplets : nb of triplets to generate\n",
    "        - triplets_per_file : number of triplet built for each selected file\n",
    "        - neg_ratio : ratio of positives / negative examples. Negative examples are taken inside the article !\n",
    "        \n",
    "    output : \n",
    "        - triplets : nd_array of triplets of shape (nb_triplets+ , embed_dim)\n",
    "        - labels : nd_array of labels of shape (nb_triplets+ ,)\n",
    "\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    labels = []\n",
    "    \n",
    "    assert nb_triplets>=triplets_per_file, \"you should have nb_triplets > triplets_per_file\"\n",
    "    \n",
    "    # nb of pos / neg triplets per file\n",
    "    neg_per_file = np.floor(triplets_per_file*neg_ratio) #number of negative triplets to generate given(query + partial summary)\n",
    "    assert neg_per_file >= 1, \"you have to increase your neg_ratio\"\n",
    "    \n",
    "    nb_files = nb_triplets / triplets_per_file\n",
    "    selected_files_array = np.random.choice(article_names, size=nb_files, p=article_weights, replace = False)\n",
    "    \n",
    "    for full_name in selected_files_array :\n",
    "        with open(full_name) as f :\n",
    "            file_as_dict = json.load(f)\n",
    "        \n",
    "        counter = 0\n",
    "        while counter < triplets_per_file :\n",
    "            \n",
    "            # select a key for positive examples\n",
    "            key_pos = select_key(file_as_dict)\n",
    "            \n",
    "            triplet = build_triplet(d2v_model, file_as_dict, key_pos, positive = True, str_mode = str_mode)\n",
    "            label = 1\n",
    "            \n",
    "            triplets.append(triplet)\n",
    "            labels.append(label)\n",
    "            counter += 1 \n",
    "            \n",
    "            if neg_ratio < 1 : \n",
    "                \n",
    "                if np.random.rand() < neg_ratio :\n",
    "                    \n",
    "                    triplet = build_triplet(d2v_model, file_as_dict, key_pos, positive = False, str_mode = str_mode)\n",
    "                    label = 0\n",
    "                    \n",
    "                    triplets.append(triplet)\n",
    "                    labels.append(label)\n",
    "                    counter += 1 \n",
    "\n",
    "            else :\n",
    "                \n",
    "                for n in range(int(np.floor(neg_ratio))):\n",
    "                    \n",
    "                    triplet = build_triplet(d2v_model, file_as_dict, key_pos, positive = False, str_mode = str_mode)\n",
    "                    label = 0\n",
    "                    \n",
    "                    triplets.append(triplet)\n",
    "                    labels.append(label)\n",
    "                    counter += 1 \n",
    "\n",
    "            \n",
    "    triplets = np.asarray(triplets)[:nb_triplets]\n",
    "    labels = np.asarray(labels)[:nb_triplets]\n",
    "    \n",
    "    return triplets, labels\n",
    "\n",
    "def build_triplet(d2v_model, file_as_dict, key_pos, positive = True, str_mode = False):\n",
    "\n",
    "    query_str = key_pos\n",
    "    query_prep = gensim.utils.simple_preprocess(query_str, deacc=True)\n",
    "    query_vector = d2v_model.infer_vector(query_prep)\n",
    "    \n",
    "    summary_str = file_as_dict[key_pos]\n",
    "    sentences = summary_str.split(\".\")\n",
    "    \n",
    "    partial_summary = []\n",
    "    candidates = []\n",
    "    \n",
    "    size_partial_summary = np.random.rand()\n",
    "    \n",
    "    for sentence in sentences: \n",
    "        if np.random.rand() < size_partial_summary :\n",
    "            partial_summary.append(sentence)\n",
    "        else :\n",
    "            candidates.append(sentence)\n",
    "    \n",
    "    candidate = \"\"\n",
    "    counter_candidate = 0\n",
    "    while (candidate == \"\" or partial_summary == \"\") and counter_candidate < 10:\n",
    "        counter_candidate += 1\n",
    "        \n",
    "        if positive : \n",
    "            if len(candidates) > 0:\n",
    "                random_candidate_index = np.random.randint(0,len(candidates))\n",
    "                candidate = candidates[random_candidate_index]\n",
    "            else :\n",
    "                random_candidate_index = np.random.randint(0,len(partial_summary))\n",
    "                candidate = partial_summary[random_candidate_index]\n",
    "                partial_summary[random_candidate_index] = \"\"\n",
    "\n",
    "\n",
    "            candidate_prep = gensim.utils.simple_preprocess(candidate, deacc=True)\n",
    "            candidate_vector = d2v_model.infer_vector(candidate_prep)\n",
    "\n",
    "        else :\n",
    "\n",
    "            key_neg = select_key(file_as_dict)\n",
    "            counter = 0\n",
    "\n",
    "            while key_neg == key_pos and counter<10 : # the counter is for the preproduction code \n",
    "                counter += 1\n",
    "                key_neg = select_key(file_as_dict)\n",
    "\n",
    "            summary_str = file_as_dict[key_neg]\n",
    "\n",
    "            sentences = summary_str.split('.')\n",
    "            random_candidate_index = np.random.randint(0,len(sentences))\n",
    "            candidate = sentences[random_candidate_index]\n",
    "            candidate_prep = gensim.utils.simple_preprocess(candidate, deacc=True)\n",
    "            candidate_vector = d2v_model.infer_vector(candidate_prep)\n",
    "        \n",
    "        partial_summary_str = \"\".join(partial_summary)\n",
    "        partial_summary_prep = gensim.utils.simple_preprocess(partial_summary_str, deacc=True)\n",
    "        partial_summary_vector = d2v_model.infer_vector(partial_summary_prep)\n",
    "    \n",
    "    if str_mode :\n",
    "        return query_str, partial_summary_str, candidate\n",
    "    else :\n",
    "        return np.hstack( [query_vector, partial_summary_vector, candidate_vector] )\n",
    "\n",
    "\n",
    "def doc_title_table(title_file):\n",
    "    with open(title_file , 'r') as f :\n",
    "        lines = f.readlines()\n",
    "        raw_text = \"\".join(l for l in lines)\n",
    "        left_idx_num = [ m.end(0) for m in re.finditer(r\"<num>\",raw_text)]\n",
    "        right_idx_num = [ m.start(0) for m in re.finditer(r\"</num>\",raw_text)]\n",
    "\n",
    "        left_idx_title = [ m.end(0) for m in re.finditer(r\"<title>\",raw_text)]\n",
    "        right_idx_title = [ m.start(0) for m in re.finditer(r\"</title>\",raw_text)]\n",
    "\n",
    "        docs_title_dict = {}\n",
    "        for i in range(len(left_idx_num)):\n",
    "            docs_title_dict[raw_text[left_idx_num[i]+1:right_idx_num[i]-1]] = raw_text[left_idx_title[i]+1:right_idx_title[i]-1]\n",
    "    return docs_title_dict\n",
    "\n",
    "def merge_articles(docs_folder):\n",
    "    \"\"\" for DUC corpus \"\"\" \n",
    "    s = \"\"\n",
    "    \n",
    "    for doc in os.listdir(docs_folder):\n",
    "        try:\n",
    "            with open(docs_folder + doc ,'r') as f:\n",
    "\n",
    "                lines = f.readlines()\n",
    "                raw_doc = \"\".join(txt for txt in lines)\n",
    "                left_idx_headline = [ m.end(0) for m in re.finditer(r\"<HEADLINE>\",raw_doc)]\n",
    "                right_idx_headline = [ m.start(0) for m in re.finditer(r\"</HEADLINE>\",raw_doc)]\n",
    "\n",
    "                left_idx_text = [ m.end(0) for m in re.finditer(r\"<TEXT>\",raw_doc)]\n",
    "                right_idx_text = [ m.start(0) for m in re.finditer(r\"</TEXT>\",raw_doc)]\n",
    "\n",
    "                raw_headline = raw_doc[left_idx_headline[0]:right_idx_headline[0]]\n",
    "                raw_text = raw_doc[left_idx_text[0]:right_idx_text[0]]\n",
    "\n",
    "                left_idx_paragraph_headline = [ m.end(0) for m in re.finditer(r\"<P>\",raw_headline)]\n",
    "                right_idx_paragraph_headline = [ m.start(0) for m in re.finditer(r\"</P>\",raw_headline)]\n",
    "\n",
    "                left_idx_paragraph_text = [ m.end(0) for m in re.finditer(r\"<P>\",raw_text)]\n",
    "                right_idx_paragraph_text = [ m.start(0) for m in re.finditer(r\"</P>\",raw_text)]\n",
    "\n",
    "                for i in range(len(left_idx_paragraph_headline)):\n",
    "                    s += raw_headline[left_idx_paragraph_headline[i]:right_idx_paragraph_headline[i]-2] + \".\"\n",
    "\n",
    "                for i in range(len(left_idx_paragraph_text)):\n",
    "                    s += raw_text[left_idx_paragraph_text[i]:right_idx_paragraph_text[i]-1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return s\n",
    "\n",
    "def summarize(text, query, d2v_model, nn_model, limit = 250):\n",
    "\n",
    "    query_prep = gensim.utils.simple_preprocess(query, deacc=True)\n",
    "    query_vector = d2v_model.infer_vector(query_prep)\n",
    "    \n",
    "    summary  = \"\"\n",
    "    summary_vector = d2v_model.infer_vector([\"\"])\n",
    "    summary_idx = []\n",
    "    \n",
    "    sentences = text.split('.')\n",
    "    sentences = np.asarray(sentences)\n",
    "    \n",
    "    remaining_sentences = copy.copy(sentences)\n",
    "    \n",
    "    size = 0\n",
    "    counter = 0\n",
    "    while size < limit and len(remaining_sentences)>0 :\n",
    "        counter = counter+1\n",
    "        scores = []\n",
    "        for sentence in remaining_sentences :\n",
    "\n",
    "            sentence_prep = gensim.utils.simple_preprocess(sentence, deacc=True)\n",
    "            sentence_vector = d2v_model.infer_vector(sentence_prep)\n",
    "\n",
    "            nn_input = np.hstack([query_vector, summary_vector, sentence_vector])\n",
    "            nn_input = np.asarray([nn_input]) # weird but it is important to do it\n",
    "            score = nn_model.predict(nn_input) \n",
    "            scores.append(score)\n",
    "        #print(scores)\n",
    "        max_idx_rem = int(np.argmax(scores))\n",
    "        idx_selected_sentence = np.arange(len(sentences))[sentences == remaining_sentences[max_idx_rem]]\n",
    "        idx_selected_sentence = int(idx_selected_sentence[0])\n",
    "        size += len(remaining_sentences[max_idx_rem].split())\n",
    "        \n",
    "        remaining_sentences = list(remaining_sentences)\n",
    "        del remaining_sentences[max_idx_rem]\n",
    "        bisect.insort_left(summary_idx,idx_selected_sentence)\n",
    "\n",
    "        summary  = \"\"\n",
    "\n",
    "        for idx in summary_idx:\n",
    "            summary = summary + \" \" + sentences[idx]\n",
    "\n",
    "        summary_prep = gensim.utils.simple_preprocess(summary, deacc=True)\n",
    "        summary_vector = d2v_model.infer_vector(summary_prep)\n",
    "\n",
    "    return summary\n",
    "\n",
    "def merge_articles_tqdfs(theme_doc_folder):\n",
    "    \"\"\" for tqdfs corpus \"\"\" \n",
    "    s = \"\"\n",
    "    for source in os.listdir(theme_doc_folder):\n",
    "        try :\n",
    "            for doc in os.listdir(theme_doc_folder + source):\n",
    "                with open(theme_doc_folder + source + \"/\" + doc ,'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    s += \"\".join(txt for txt in lines)\n",
    "                s += \" \"\n",
    "        except:\n",
    "            pass\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_queries(query_txt_file):\n",
    "    with open(query_txt_file, 'r') as f :\n",
    "        queries = f.readlines()\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "## loading a d2vmodel (to be a shifted LSTM next ...)\n",
    "\n",
    "# parameters of doc2vec\n",
    "dm = 0\n",
    "min_count = 5\n",
    "window = 10\n",
    "size = 400\n",
    "sample = 1e-4\n",
    "negative = 5\n",
    "workers = 4\n",
    "epoch = 20\n",
    "\n",
    "# Initialize the model ( IMPORTANT )\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec(dm=dm,min_count=min_count, window=window, size=size, sample=sample, negative=negative, workers=workers,iter = epoch)\n",
    "\n",
    "# load model\n",
    "model_name =\"dm_\"+str(dm)+\"_mc_\"+str(min_count)+\"_w_\"+str(window)+\"_size_\"+str(size)+\"_neg_\"+str(negative)+\"_ep_\"+str(epoch)\n",
    "try :\n",
    "    d2v_model = d2v_model.load(lang_model_folder+model_name+\".d2v\")\n",
    "except :\n",
    "    print \"try a model in : \", os.listdir(lang_model_folder)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = Sequential()\n",
    "\n",
    "fc_model.add(Dense(120, input_dim=1200))\n",
    "fc_model.add(Activation('sigmoid'))\n",
    "fc_model.add(Dropout(0.5))\n",
    "\n",
    "fc_model.add(Dense(12))\n",
    "fc_model.add(Activation('sigmoid'))\n",
    "fc_model.add(Dropout(0.5))\n",
    "\n",
    "fc_model.add(Dense(1))\n",
    "fc_model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fc_model.load_weights(nn_summarizers_folder + \"fc_model_batch_21k_R2_0.09297_SU4_0.08988.hdf5\")\n",
    "fc_model.load_weights(nn_summarizers_folder + \"fc_model_batch_103k_R2_0.06574_SU4_0.08636.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/alz.1.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/alz.2.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/alz.3.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/alz.4.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/alz.5.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/alz.6.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/alz.7.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/alz.8.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/asthma.1.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/asthma.2.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/asthma.3.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/asthma.4.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/asthma.5.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/asthma.6.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/asthma.7.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/asthma.8.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/asthma.9.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.1.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.2.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.3.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.4.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.5.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.6.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.7.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.8.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.9.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.10.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/cancer.11.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.1.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.2.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.3.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.4.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.5.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.6.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.7.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.8.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.9.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.10.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.11.txt\n",
      "writing in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_25_05_38_test/obese.12.txt\n"
     ]
    }
   ],
   "source": [
    "for theme in themes :\n",
    "    theme_folder = tdqfs_folder + theme + \"/\"\n",
    "    theme_doc_folder = theme_folder + theme + \"/\"\n",
    "    queries = get_queries(theme_folder+\"queries.txt\")\n",
    "    text = merge_articles_tqdfs(theme_doc_folder)\n",
    "    for i in range(len(queries)):\n",
    "        query = queries[i]\n",
    "        summary = summarize(text,query,d2v_model, fc_model, limit = 250)\n",
    "        summary = \" \".join(summary.split()[:250])\n",
    "        \n",
    "        summary_name = theme + \".\" + str(i+1) + \".txt\"\n",
    "        with open(system_folder + summary_name,'w') as f :\n",
    "            f.write(summary.decode('ascii',\"ignore\").encode(\"utf8\", \"replace\"))\n",
    "            print 'writing in '+ system_folder + summary_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform rouge\n",
    "r = Rouge155()\n",
    "r.system_dir = \"/home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_21_15_13_test\"\n",
    "r.model_dir = model_dir\n",
    "r.model_filename_pattern = '#ID#.u[0-9]q[0-9].txt'\n",
    "r.system_filename_pattern = '([a-z]+.[0-9]+).txt'\n",
    "\n",
    "#options = \"-n 4 -m -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0 -a -x\" #porter stemmer pose pb\n",
    "\n",
    "#options =  '-a -d -e ' + r._data_dir + ' -m -n 2 -s -2 4 -u -x -f A'\n",
    "\n",
    "options = \"-e \" + r._data_dir + \" -n 4 -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0 -a -x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-09-25 05:43:45,235 [MainThread  ] [INFO ]  Writing summaries.\n",
      "INFO:global:Writing summaries.\n",
      "2016-09-25 05:43:45,236 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpdq29DW/system and model files to /tmp/tmpdq29DW/model.\n",
      "INFO:global:Processing summaries. Saving system files to /tmp/tmpdq29DW/system and model files to /tmp/tmpdq29DW/model.\n",
      "2016-09-25 05:43:45,237 [MainThread  ] [INFO ]  Processing files in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_21_15_13_test.\n",
      "INFO:global:Processing files in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_system/2016_09_21_15_13_test.\n",
      "2016-09-25 05:43:45,237 [MainThread  ] [INFO ]  Processing cancer.9.txt.\n",
      "INFO:global:Processing cancer.9.txt.\n",
      "2016-09-25 05:43:45,238 [MainThread  ] [INFO ]  Processing asthma.5.txt.\n",
      "INFO:global:Processing asthma.5.txt.\n",
      "2016-09-25 05:43:45,239 [MainThread  ] [INFO ]  Processing obese.6.txt.\n",
      "INFO:global:Processing obese.6.txt.\n",
      "2016-09-25 05:43:45,240 [MainThread  ] [INFO ]  Processing alz.4.txt.\n",
      "INFO:global:Processing alz.4.txt.\n",
      "2016-09-25 05:43:45,241 [MainThread  ] [INFO ]  Processing cancer.1.txt.\n",
      "INFO:global:Processing cancer.1.txt.\n",
      "2016-09-25 05:43:45,242 [MainThread  ] [INFO ]  Processing cancer.2.txt.\n",
      "INFO:global:Processing cancer.2.txt.\n",
      "2016-09-25 05:43:45,244 [MainThread  ] [INFO ]  Processing obese.5.txt.\n",
      "INFO:global:Processing obese.5.txt.\n",
      "2016-09-25 05:43:45,245 [MainThread  ] [INFO ]  Processing asthma.8.txt.\n",
      "INFO:global:Processing asthma.8.txt.\n",
      "2016-09-25 05:43:45,245 [MainThread  ] [INFO ]  Processing alz.6.txt.\n",
      "INFO:global:Processing alz.6.txt.\n",
      "2016-09-25 05:43:45,246 [MainThread  ] [INFO ]  Processing cancer.7.txt.\n",
      "INFO:global:Processing cancer.7.txt.\n",
      "2016-09-25 05:43:45,247 [MainThread  ] [INFO ]  Processing cancer.10.txt.\n",
      "INFO:global:Processing cancer.10.txt.\n",
      "2016-09-25 05:43:45,247 [MainThread  ] [INFO ]  Processing obese.3.txt.\n",
      "INFO:global:Processing obese.3.txt.\n",
      "2016-09-25 05:43:45,248 [MainThread  ] [INFO ]  Processing cancer.4.txt.\n",
      "INFO:global:Processing cancer.4.txt.\n",
      "2016-09-25 05:43:45,249 [MainThread  ] [INFO ]  Processing obese.9.txt.\n",
      "INFO:global:Processing obese.9.txt.\n",
      "2016-09-25 05:43:45,249 [MainThread  ] [INFO ]  Processing asthma.9.txt.\n",
      "INFO:global:Processing asthma.9.txt.\n",
      "2016-09-25 05:43:45,250 [MainThread  ] [INFO ]  Processing alz.2.txt.\n",
      "INFO:global:Processing alz.2.txt.\n",
      "2016-09-25 05:43:45,251 [MainThread  ] [INFO ]  Processing alz.1.txt.\n",
      "INFO:global:Processing alz.1.txt.\n",
      "2016-09-25 05:43:45,251 [MainThread  ] [INFO ]  Processing cancer.8.txt.\n",
      "INFO:global:Processing cancer.8.txt.\n",
      "2016-09-25 05:43:45,252 [MainThread  ] [INFO ]  Processing asthma.1.txt.\n",
      "INFO:global:Processing asthma.1.txt.\n",
      "2016-09-25 05:43:45,253 [MainThread  ] [INFO ]  Processing asthma.7.txt.\n",
      "INFO:global:Processing asthma.7.txt.\n",
      "2016-09-25 05:43:45,253 [MainThread  ] [INFO ]  Processing obese.11.txt.\n",
      "INFO:global:Processing obese.11.txt.\n",
      "2016-09-25 05:43:45,254 [MainThread  ] [INFO ]  Processing asthma.6.txt.\n",
      "INFO:global:Processing asthma.6.txt.\n",
      "2016-09-25 05:43:45,255 [MainThread  ] [INFO ]  Processing obese.4.txt.\n",
      "INFO:global:Processing obese.4.txt.\n",
      "2016-09-25 05:43:45,255 [MainThread  ] [INFO ]  Processing asthma.4.txt.\n",
      "INFO:global:Processing asthma.4.txt.\n",
      "2016-09-25 05:43:45,256 [MainThread  ] [INFO ]  Processing cancer.3.txt.\n",
      "INFO:global:Processing cancer.3.txt.\n",
      "2016-09-25 05:43:45,257 [MainThread  ] [INFO ]  Processing obese.10.txt.\n",
      "INFO:global:Processing obese.10.txt.\n",
      "2016-09-25 05:43:45,257 [MainThread  ] [INFO ]  Processing obese.1.txt.\n",
      "INFO:global:Processing obese.1.txt.\n",
      "2016-09-25 05:43:45,258 [MainThread  ] [INFO ]  Processing cancer.6.txt.\n",
      "INFO:global:Processing cancer.6.txt.\n",
      "2016-09-25 05:43:45,259 [MainThread  ] [INFO ]  Processing obese.7.txt.\n",
      "INFO:global:Processing obese.7.txt.\n",
      "2016-09-25 05:43:45,259 [MainThread  ] [INFO ]  Processing alz.7.txt.\n",
      "INFO:global:Processing alz.7.txt.\n",
      "2016-09-25 05:43:45,260 [MainThread  ] [INFO ]  Processing alz.5.txt.\n",
      "INFO:global:Processing alz.5.txt.\n",
      "2016-09-25 05:43:45,261 [MainThread  ] [INFO ]  Processing alz.3.txt.\n",
      "INFO:global:Processing alz.3.txt.\n",
      "2016-09-25 05:43:45,261 [MainThread  ] [INFO ]  Processing cancer.11.txt.\n",
      "INFO:global:Processing cancer.11.txt.\n",
      "2016-09-25 05:43:45,262 [MainThread  ] [INFO ]  Processing obese.12.txt.\n",
      "INFO:global:Processing obese.12.txt.\n",
      "2016-09-25 05:43:45,263 [MainThread  ] [INFO ]  Processing obese.2.txt.\n",
      "INFO:global:Processing obese.2.txt.\n",
      "2016-09-25 05:43:45,263 [MainThread  ] [INFO ]  Processing alz.8.txt.\n",
      "INFO:global:Processing alz.8.txt.\n",
      "2016-09-25 05:43:45,264 [MainThread  ] [INFO ]  Processing obese.8.txt.\n",
      "INFO:global:Processing obese.8.txt.\n",
      "2016-09-25 05:43:45,265 [MainThread  ] [INFO ]  Processing asthma.3.txt.\n",
      "INFO:global:Processing asthma.3.txt.\n",
      "2016-09-25 05:43:45,265 [MainThread  ] [INFO ]  Processing cancer.5.txt.\n",
      "INFO:global:Processing cancer.5.txt.\n",
      "2016-09-25 05:43:45,266 [MainThread  ] [INFO ]  Processing asthma.2.txt.\n",
      "INFO:global:Processing asthma.2.txt.\n",
      "2016-09-25 05:43:45,267 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpdq29DW/system.\n",
      "INFO:global:Saved processed files to /tmp/tmpdq29DW/system.\n",
      "2016-09-25 05:43:45,267 [MainThread  ] [INFO ]  Processing files in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_model.\n",
      "INFO:global:Processing files in /home/ubuntu/summarization_query_oriented/data/TD-QFS/tdqfs_summary_model.\n",
      "2016-09-25 05:43:45,268 [MainThread  ] [INFO ]  Processing cancer.10.u2q1.txt.\n",
      "INFO:global:Processing cancer.10.u2q1.txt.\n",
      "2016-09-25 05:43:45,268 [MainThread  ] [INFO ]  Processing asthma.5.u3q2.txt.\n",
      "INFO:global:Processing asthma.5.u3q2.txt.\n",
      "2016-09-25 05:43:45,269 [MainThread  ] [INFO ]  Processing obese.4.u2q2.txt.\n",
      "INFO:global:Processing obese.4.u2q2.txt.\n",
      "2016-09-25 05:43:45,270 [MainThread  ] [INFO ]  Processing asthma.4.u1q3.txt.\n",
      "INFO:global:Processing asthma.4.u1q3.txt.\n",
      "2016-09-25 05:43:45,270 [MainThread  ] [INFO ]  Processing cancer.6.u1q2.txt.\n",
      "INFO:global:Processing cancer.6.u1q2.txt.\n",
      "2016-09-25 05:43:45,271 [MainThread  ] [INFO ]  Processing obese.5.u1q2.txt.\n",
      "INFO:global:Processing obese.5.u1q2.txt.\n",
      "2016-09-25 05:43:45,272 [MainThread  ] [INFO ]  Processing alz.1.u1q3.txt.\n",
      "INFO:global:Processing alz.1.u1q3.txt.\n",
      "2016-09-25 05:43:45,273 [MainThread  ] [INFO ]  Processing alz.3.u3q1.txt.\n",
      "INFO:global:Processing alz.3.u3q1.txt.\n",
      "2016-09-25 05:43:45,273 [MainThread  ] [INFO ]  Processing cancer.4.u3q3.txt.\n",
      "INFO:global:Processing cancer.4.u3q3.txt.\n",
      "2016-09-25 05:43:45,274 [MainThread  ] [INFO ]  Processing alz.2.u2q2.txt.\n",
      "INFO:global:Processing alz.2.u2q2.txt.\n",
      "2016-09-25 05:43:45,275 [MainThread  ] [INFO ]  Processing asthma.2.u1q2.txt.\n",
      "INFO:global:Processing asthma.2.u1q2.txt.\n",
      "2016-09-25 05:43:45,275 [MainThread  ] [INFO ]  Processing obese.10.u1q1.txt.\n",
      "INFO:global:Processing obese.10.u1q1.txt.\n",
      "2016-09-25 05:43:45,276 [MainThread  ] [INFO ]  Processing alz.3.u2q2.txt.\n",
      "INFO:global:Processing alz.3.u2q2.txt.\n",
      "2016-09-25 05:43:45,277 [MainThread  ] [INFO ]  Processing asthma.4.u2q2.txt.\n",
      "INFO:global:Processing asthma.4.u2q2.txt.\n",
      "2016-09-25 05:43:45,277 [MainThread  ] [INFO ]  Processing obese.3.u1q2.txt.\n",
      "INFO:global:Processing obese.3.u1q2.txt.\n",
      "2016-09-25 05:43:45,278 [MainThread  ] [INFO ]  Processing alz.2.u1q1.txt.\n",
      "INFO:global:Processing alz.2.u1q1.txt.\n",
      "2016-09-25 05:43:45,279 [MainThread  ] [INFO ]  Processing obese.3.u3q1.txt.\n",
      "INFO:global:Processing obese.3.u3q1.txt.\n",
      "2016-09-25 05:43:45,279 [MainThread  ] [INFO ]  Processing cancer.8.u3q1.txt.\n",
      "INFO:global:Processing cancer.8.u3q1.txt.\n",
      "2016-09-25 05:43:45,280 [MainThread  ] [INFO ]  Processing obese.5.u2q2.txt.\n",
      "INFO:global:Processing obese.5.u2q2.txt.\n",
      "2016-09-25 05:43:45,281 [MainThread  ] [INFO ]  Processing alz.2.u3q3.txt.\n",
      "INFO:global:Processing alz.2.u3q3.txt.\n",
      "2016-09-25 05:43:45,281 [MainThread  ] [INFO ]  Processing obese.6.u1q2.txt.\n",
      "INFO:global:Processing obese.6.u1q2.txt.\n",
      "2016-09-25 05:43:45,282 [MainThread  ] [INFO ]  Processing alz.1.u3q3.txt.\n",
      "INFO:global:Processing alz.1.u3q3.txt.\n",
      "2016-09-25 05:43:45,283 [MainThread  ] [INFO ]  Processing cancer.4.u2q2.txt.\n",
      "INFO:global:Processing cancer.4.u2q2.txt.\n",
      "2016-09-25 05:43:45,283 [MainThread  ] [INFO ]  Processing obese.3.u1q1.txt.\n",
      "INFO:global:Processing obese.3.u1q1.txt.\n",
      "2016-09-25 05:43:45,284 [MainThread  ] [INFO ]  Processing obese.3.u2q1.txt.\n",
      "INFO:global:Processing obese.3.u2q1.txt.\n",
      "2016-09-25 05:43:45,285 [MainThread  ] [INFO ]  Processing obese.4.u1q3.txt.\n",
      "INFO:global:Processing obese.4.u1q3.txt.\n",
      "2016-09-25 05:43:45,285 [MainThread  ] [INFO ]  Processing cancer.2.u1q1.txt.\n",
      "INFO:global:Processing cancer.2.u1q1.txt.\n",
      "2016-09-25 05:43:45,286 [MainThread  ] [INFO ]  Processing obese.4.u2q3.txt.\n",
      "INFO:global:Processing obese.4.u2q3.txt.\n",
      "2016-09-25 05:43:45,287 [MainThread  ] [INFO ]  Processing obese.3.u3q3.txt.\n",
      "INFO:global:Processing obese.3.u3q3.txt.\n",
      "2016-09-25 05:43:45,287 [MainThread  ] [INFO ]  Processing asthma.2.u3q3.txt.\n",
      "INFO:global:Processing asthma.2.u3q3.txt.\n",
      "2016-09-25 05:43:45,288 [MainThread  ] [INFO ]  Processing obese.5.u1q1.txt.\n",
      "INFO:global:Processing obese.5.u1q1.txt.\n",
      "2016-09-25 05:43:45,289 [MainThread  ] [INFO ]  Processing obese.5.u3q1.txt.\n",
      "INFO:global:Processing obese.5.u3q1.txt.\n",
      "2016-09-25 05:43:45,289 [MainThread  ] [INFO ]  Processing asthma.4.u2q3.txt.\n",
      "INFO:global:Processing asthma.4.u2q3.txt.\n",
      "2016-09-25 05:43:45,290 [MainThread  ] [INFO ]  Processing cancer.1.u3q1.txt.\n",
      "INFO:global:Processing cancer.1.u3q1.txt.\n",
      "2016-09-25 05:43:45,291 [MainThread  ] [INFO ]  Processing cancer.11.u3q1.txt.\n",
      "INFO:global:Processing cancer.11.u3q1.txt.\n",
      "2016-09-25 05:43:45,291 [MainThread  ] [INFO ]  Processing alz.4.u1q2.txt.\n",
      "INFO:global:Processing alz.4.u1q2.txt.\n",
      "2016-09-25 05:43:45,292 [MainThread  ] [INFO ]  Processing alz.1.u1q2.txt.\n",
      "INFO:global:Processing alz.1.u1q2.txt.\n",
      "2016-09-25 05:43:45,293 [MainThread  ] [INFO ]  Processing alz.2.u1q3.txt.\n",
      "INFO:global:Processing alz.2.u1q3.txt.\n",
      "2016-09-25 05:43:45,293 [MainThread  ] [INFO ]  Processing obese.3.u3q2.txt.\n",
      "INFO:global:Processing obese.3.u3q2.txt.\n",
      "2016-09-25 05:43:45,294 [MainThread  ] [INFO ]  Processing obese.9.u3q1.txt.\n",
      "INFO:global:Processing obese.9.u3q1.txt.\n",
      "2016-09-25 05:43:45,295 [MainThread  ] [INFO ]  Processing alz.8.u3q1.txt.\n",
      "INFO:global:Processing alz.8.u3q1.txt.\n",
      "2016-09-25 05:43:45,295 [MainThread  ] [INFO ]  Processing obese.11.u1q1.txt.\n",
      "INFO:global:Processing obese.11.u1q1.txt.\n",
      "2016-09-25 05:43:45,296 [MainThread  ] [INFO ]  Processing asthma.6.u3q1.txt.\n",
      "INFO:global:Processing asthma.6.u3q1.txt.\n",
      "2016-09-25 05:43:45,297 [MainThread  ] [INFO ]  Processing cancer.2.u1q2.txt.\n",
      "INFO:global:Processing cancer.2.u1q2.txt.\n",
      "2016-09-25 05:43:45,298 [MainThread  ] [INFO ]  Processing cancer.8.u2q1.txt.\n",
      "INFO:global:Processing cancer.8.u2q1.txt.\n",
      "2016-09-25 05:43:45,298 [MainThread  ] [INFO ]  Processing cancer.1.u2q2.txt.\n",
      "INFO:global:Processing cancer.1.u2q2.txt.\n",
      "2016-09-25 05:43:45,299 [MainThread  ] [INFO ]  Processing obese.6.u3q2.txt.\n",
      "INFO:global:Processing obese.6.u3q2.txt.\n",
      "2016-09-25 05:43:45,300 [MainThread  ] [INFO ]  Processing asthma.5.u1q1.txt.\n",
      "INFO:global:Processing asthma.5.u1q1.txt.\n",
      "2016-09-25 05:43:45,300 [MainThread  ] [INFO ]  Processing cancer.6.u1q3.txt.\n",
      "INFO:global:Processing cancer.6.u1q3.txt.\n",
      "2016-09-25 05:43:45,301 [MainThread  ] [INFO ]  Processing asthma.4.u3q3.txt.\n",
      "INFO:global:Processing asthma.4.u3q3.txt.\n",
      "2016-09-25 05:43:45,302 [MainThread  ] [INFO ]  Processing obese.6.u2q2.txt.\n",
      "INFO:global:Processing obese.6.u2q2.txt.\n",
      "2016-09-25 05:43:45,302 [MainThread  ] [INFO ]  Processing cancer.1.u2q3.txt.\n",
      "INFO:global:Processing cancer.1.u2q3.txt.\n",
      "2016-09-25 05:43:45,303 [MainThread  ] [INFO ]  Processing asthma.9.u1q1.txt.\n",
      "INFO:global:Processing asthma.9.u1q1.txt.\n",
      "2016-09-25 05:43:45,304 [MainThread  ] [INFO ]  Processing alz.1.u3q2.txt.\n",
      "INFO:global:Processing alz.1.u3q2.txt.\n",
      "2016-09-25 05:43:45,304 [MainThread  ] [INFO ]  Processing asthma.3.u2q1.txt.\n",
      "INFO:global:Processing asthma.3.u2q1.txt.\n",
      "2016-09-25 05:43:45,305 [MainThread  ] [INFO ]  Processing alz.3.u2q1.txt.\n",
      "INFO:global:Processing alz.3.u2q1.txt.\n",
      "2016-09-25 05:43:45,306 [MainThread  ] [INFO ]  Processing obese.6.u1q1.txt.\n",
      "INFO:global:Processing obese.6.u1q1.txt.\n",
      "2016-09-25 05:43:45,306 [MainThread  ] [INFO ]  Processing obese.6.u3q1.txt.\n",
      "INFO:global:Processing obese.6.u3q1.txt.\n",
      "2016-09-25 05:43:45,307 [MainThread  ] [INFO ]  Processing asthma.1.u1q3.txt.\n",
      "INFO:global:Processing asthma.1.u1q3.txt.\n",
      "2016-09-25 05:43:45,308 [MainThread  ] [INFO ]  Processing cancer.3.u2q1.txt.\n",
      "INFO:global:Processing cancer.3.u2q1.txt.\n",
      "2016-09-25 05:43:45,308 [MainThread  ] [INFO ]  Processing cancer.7.u1q1.txt.\n",
      "INFO:global:Processing cancer.7.u1q1.txt.\n",
      "2016-09-25 05:43:45,309 [MainThread  ] [INFO ]  Processing alz.3.u1q2.txt.\n",
      "INFO:global:Processing alz.3.u1q2.txt.\n",
      "2016-09-25 05:43:45,310 [MainThread  ] [INFO ]  Processing cancer.10.u1q1.txt.\n",
      "INFO:global:Processing cancer.10.u1q1.txt.\n",
      "2016-09-25 05:43:45,310 [MainThread  ] [INFO ]  Processing cancer.3.u3q2.txt.\n",
      "INFO:global:Processing cancer.3.u3q2.txt.\n",
      "2016-09-25 05:43:45,311 [MainThread  ] [INFO ]  Processing alz.3.u1q3.txt.\n",
      "INFO:global:Processing alz.3.u1q3.txt.\n",
      "2016-09-25 05:43:45,312 [MainThread  ] [INFO ]  Processing asthma.4.u1q2.txt.\n",
      "INFO:global:Processing asthma.4.u1q2.txt.\n",
      "2016-09-25 05:43:45,312 [MainThread  ] [INFO ]  Processing obese.9.u1q1.txt.\n",
      "INFO:global:Processing obese.9.u1q1.txt.\n",
      "2016-09-25 05:43:45,313 [MainThread  ] [INFO ]  Processing obese.1.u1q1.txt.\n",
      "INFO:global:Processing obese.1.u1q1.txt.\n",
      "2016-09-25 05:43:45,314 [MainThread  ] [INFO ]  Processing cancer.9.u1q1.txt.\n",
      "INFO:global:Processing cancer.9.u1q1.txt.\n",
      "2016-09-25 05:43:45,315 [MainThread  ] [INFO ]  Processing alz.4.u2q3.txt.\n",
      "INFO:global:Processing alz.4.u2q3.txt.\n",
      "2016-09-25 05:43:45,315 [MainThread  ] [INFO ]  Processing obese.11.u2q1.txt.\n",
      "INFO:global:Processing obese.11.u2q1.txt.\n",
      "2016-09-25 05:43:45,316 [MainThread  ] [INFO ]  Processing obese.7.u3q1.txt.\n",
      "INFO:global:Processing obese.7.u3q1.txt.\n",
      "2016-09-25 05:43:45,317 [MainThread  ] [INFO ]  Processing cancer.2.u2q2.txt.\n",
      "INFO:global:Processing cancer.2.u2q2.txt.\n",
      "2016-09-25 05:43:45,317 [MainThread  ] [INFO ]  Processing cancer.2.u3q1.txt.\n",
      "INFO:global:Processing cancer.2.u3q1.txt.\n",
      "2016-09-25 05:43:45,318 [MainThread  ] [INFO ]  Processing cancer.3.u1q1.txt.\n",
      "INFO:global:Processing cancer.3.u1q1.txt.\n",
      "2016-09-25 05:43:45,319 [MainThread  ] [INFO ]  Processing cancer.11.u1q1.txt.\n",
      "INFO:global:Processing cancer.11.u1q1.txt.\n",
      "2016-09-25 05:43:45,319 [MainThread  ] [INFO ]  Processing asthma.1.u2q3.txt.\n",
      "INFO:global:Processing asthma.1.u2q3.txt.\n",
      "2016-09-25 05:43:45,320 [MainThread  ] [INFO ]  Processing alz.7.u1q1.txt.\n",
      "INFO:global:Processing alz.7.u1q1.txt.\n",
      "2016-09-25 05:43:45,321 [MainThread  ] [INFO ]  Processing asthma.4.u3q2.txt.\n",
      "INFO:global:Processing asthma.4.u3q2.txt.\n",
      "2016-09-25 05:43:45,321 [MainThread  ] [INFO ]  Processing cancer.6.u1q1.txt.\n",
      "INFO:global:Processing cancer.6.u1q1.txt.\n",
      "2016-09-25 05:43:45,322 [MainThread  ] [INFO ]  Processing alz.3.u2q3.txt.\n",
      "INFO:global:Processing alz.3.u2q3.txt.\n",
      "2016-09-25 05:43:45,323 [MainThread  ] [INFO ]  Processing cancer.5.u1q2.txt.\n",
      "INFO:global:Processing cancer.5.u1q2.txt.\n",
      "2016-09-25 05:43:45,323 [MainThread  ] [INFO ]  Processing alz.4.u1q3.txt.\n",
      "INFO:global:Processing alz.4.u1q3.txt.\n",
      "2016-09-25 05:43:45,324 [MainThread  ] [INFO ]  Processing obese.4.u3q2.txt.\n",
      "INFO:global:Processing obese.4.u3q2.txt.\n",
      "2016-09-25 05:43:45,325 [MainThread  ] [INFO ]  Processing asthma.3.u3q2.txt.\n",
      "INFO:global:Processing asthma.3.u3q2.txt.\n",
      "2016-09-25 05:43:45,325 [MainThread  ] [INFO ]  Processing alz.5.u3q1.txt.\n",
      "INFO:global:Processing alz.5.u3q1.txt.\n",
      "2016-09-25 05:43:45,326 [MainThread  ] [INFO ]  Processing alz.6.u3q1.txt.\n",
      "INFO:global:Processing alz.6.u3q1.txt.\n",
      "2016-09-25 05:43:45,327 [MainThread  ] [INFO ]  Processing alz.5.u2q1.txt.\n",
      "INFO:global:Processing alz.5.u2q1.txt.\n",
      "2016-09-25 05:43:45,327 [MainThread  ] [INFO ]  Processing obese.6.u2q1.txt.\n",
      "INFO:global:Processing obese.6.u2q1.txt.\n",
      "2016-09-25 05:43:45,328 [MainThread  ] [INFO ]  Processing cancer.5.u3q1.txt.\n",
      "INFO:global:Processing cancer.5.u3q1.txt.\n",
      "2016-09-25 05:43:45,329 [MainThread  ] [INFO ]  Processing asthma.1.u1q2.txt.\n",
      "INFO:global:Processing asthma.1.u1q2.txt.\n",
      "2016-09-25 05:43:45,329 [MainThread  ] [INFO ]  Processing alz.4.u3q1.txt.\n",
      "INFO:global:Processing alz.4.u3q1.txt.\n",
      "2016-09-25 05:43:45,330 [MainThread  ] [INFO ]  Processing asthma.1.u1q1.txt.\n",
      "INFO:global:Processing asthma.1.u1q1.txt.\n",
      "2016-09-25 05:43:45,331 [MainThread  ] [INFO ]  Processing asthma.8.u2q1.txt.\n",
      "INFO:global:Processing asthma.8.u2q1.txt.\n",
      "2016-09-25 05:43:45,331 [MainThread  ] [INFO ]  Processing alz.4.u3q2.txt.\n",
      "INFO:global:Processing alz.4.u3q2.txt.\n",
      "2016-09-25 05:43:45,332 [MainThread  ] [INFO ]  Processing alz.1.u3q1.txt.\n",
      "INFO:global:Processing alz.1.u3q1.txt.\n",
      "2016-09-25 05:43:45,333 [MainThread  ] [INFO ]  Processing cancer.1.u1q2.txt.\n",
      "INFO:global:Processing cancer.1.u1q2.txt.\n",
      "2016-09-25 05:43:45,333 [MainThread  ] [INFO ]  Processing alz.3.u3q3.txt.\n",
      "INFO:global:Processing alz.3.u3q3.txt.\n",
      "2016-09-25 05:43:45,334 [MainThread  ] [INFO ]  Processing asthma.7.u1q1.txt.\n",
      "INFO:global:Processing asthma.7.u1q1.txt.\n",
      "2016-09-25 05:43:45,335 [MainThread  ] [INFO ]  Processing cancer.9.u2q1.txt.\n",
      "INFO:global:Processing cancer.9.u2q1.txt.\n",
      "2016-09-25 05:43:45,336 [MainThread  ] [INFO ]  Processing cancer.3.u2q2.txt.\n",
      "INFO:global:Processing cancer.3.u2q2.txt.\n",
      "2016-09-25 05:43:45,336 [MainThread  ] [INFO ]  Processing obese.6.u2q3.txt.\n",
      "INFO:global:Processing obese.6.u2q3.txt.\n",
      "2016-09-25 05:43:45,337 [MainThread  ] [INFO ]  Processing alz.1.u2q3.txt.\n",
      "INFO:global:Processing alz.1.u2q3.txt.\n",
      "2016-09-25 05:43:45,338 [MainThread  ] [INFO ]  Processing asthma.6.u1q1.txt.\n",
      "INFO:global:Processing asthma.6.u1q1.txt.\n",
      "2016-09-25 05:43:45,338 [MainThread  ] [INFO ]  Processing alz.8.u1q1.txt.\n",
      "INFO:global:Processing alz.8.u1q1.txt.\n",
      "2016-09-25 05:43:45,339 [MainThread  ] [INFO ]  Processing alz.4.u2q1.txt.\n",
      "INFO:global:Processing alz.4.u2q1.txt.\n",
      "2016-09-25 05:43:45,340 [MainThread  ] [INFO ]  Processing obese.10.u3q1.txt.\n",
      "INFO:global:Processing obese.10.u3q1.txt.\n",
      "2016-09-25 05:43:45,340 [MainThread  ] [INFO ]  Processing obese.1.u3q1.txt.\n",
      "INFO:global:Processing obese.1.u3q1.txt.\n",
      "2016-09-25 05:43:45,341 [MainThread  ] [INFO ]  Processing cancer.1.u1q1.txt.\n",
      "INFO:global:Processing cancer.1.u1q1.txt.\n",
      "2016-09-25 05:43:45,342 [MainThread  ] [INFO ]  Processing cancer.8.u1q1.txt.\n",
      "INFO:global:Processing cancer.8.u1q1.txt.\n",
      "2016-09-25 05:43:45,342 [MainThread  ] [INFO ]  Processing obese.1.u2q2.txt.\n",
      "INFO:global:Processing obese.1.u2q2.txt.\n",
      "2016-09-25 05:43:45,343 [MainThread  ] [INFO ]  Processing asthma.3.u3q1.txt.\n",
      "INFO:global:Processing asthma.3.u3q1.txt.\n",
      "2016-09-25 05:43:45,344 [MainThread  ] [INFO ]  Processing asthma.2.u1q1.txt.\n",
      "INFO:global:Processing asthma.2.u1q1.txt.\n",
      "2016-09-25 05:43:45,345 [MainThread  ] [INFO ]  Processing obese.8.u1q1.txt.\n",
      "INFO:global:Processing obese.8.u1q1.txt.\n",
      "2016-09-25 05:43:45,345 [MainThread  ] [INFO ]  Processing asthma.1.u4q1.txt.\n",
      "INFO:global:Processing asthma.1.u4q1.txt.\n",
      "2016-09-25 05:43:45,346 [MainThread  ] [INFO ]  Processing obese.4.u3q1.txt.\n",
      "INFO:global:Processing obese.4.u3q1.txt.\n",
      "2016-09-25 05:43:45,347 [MainThread  ] [INFO ]  Processing asthma.1.u4q2.txt.\n",
      "INFO:global:Processing asthma.1.u4q2.txt.\n",
      "2016-09-25 05:43:45,347 [MainThread  ] [INFO ]  Processing cancer.7.u2q1.txt.\n",
      "INFO:global:Processing cancer.7.u2q1.txt.\n",
      "2016-09-25 05:43:45,348 [MainThread  ] [INFO ]  Processing cancer.5.u1q3.txt.\n",
      "INFO:global:Processing cancer.5.u1q3.txt.\n",
      "2016-09-25 05:43:45,349 [MainThread  ] [INFO ]  Processing cancer.5.u1q1.txt.\n",
      "INFO:global:Processing cancer.5.u1q1.txt.\n",
      "2016-09-25 05:43:45,349 [MainThread  ] [INFO ]  Processing obese.11.u3q1.txt.\n",
      "INFO:global:Processing obese.11.u3q1.txt.\n",
      "2016-09-25 05:43:45,350 [MainThread  ] [INFO ]  Processing cancer.4.u1q1.txt.\n",
      "INFO:global:Processing cancer.4.u1q1.txt.\n",
      "2016-09-25 05:43:45,351 [MainThread  ] [INFO ]  Processing asthma.4.u3q1.txt.\n",
      "INFO:global:Processing asthma.4.u3q1.txt.\n",
      "2016-09-25 05:43:45,351 [MainThread  ] [INFO ]  Processing asthma.8.u1q1.txt.\n",
      "INFO:global:Processing asthma.8.u1q1.txt.\n",
      "2016-09-25 05:43:45,352 [MainThread  ] [INFO ]  Processing asthma.9.u3q1.txt.\n",
      "INFO:global:Processing asthma.9.u3q1.txt.\n",
      "2016-09-25 05:43:45,353 [MainThread  ] [INFO ]  Processing asthma.5.u2q1.txt.\n",
      "INFO:global:Processing asthma.5.u2q1.txt.\n",
      "2016-09-25 05:43:45,353 [MainThread  ] [INFO ]  Processing alz.7.u2q1.txt.\n",
      "INFO:global:Processing alz.7.u2q1.txt.\n",
      "2016-09-25 05:43:45,354 [MainThread  ] [INFO ]  Processing obese.3.u2q3.txt.\n",
      "INFO:global:Processing obese.3.u2q3.txt.\n",
      "2016-09-25 05:43:45,355 [MainThread  ] [INFO ]  Processing obese.2.u3q2.txt.\n",
      "INFO:global:Processing obese.2.u3q2.txt.\n",
      "2016-09-25 05:43:45,355 [MainThread  ] [INFO ]  Processing asthma.3.u2q2.txt.\n",
      "INFO:global:Processing asthma.3.u2q2.txt.\n",
      "2016-09-25 05:43:45,356 [MainThread  ] [INFO ]  Processing alz.6.u2q1.txt.\n",
      "INFO:global:Processing alz.6.u2q1.txt.\n",
      "2016-09-25 05:43:45,357 [MainThread  ] [INFO ]  Processing asthma.7.u3q1.txt.\n",
      "INFO:global:Processing asthma.7.u3q1.txt.\n",
      "2016-09-25 05:43:45,357 [MainThread  ] [INFO ]  Processing cancer.3.u1q3.txt.\n",
      "INFO:global:Processing cancer.3.u1q3.txt.\n",
      "2016-09-25 05:43:45,358 [MainThread  ] [INFO ]  Processing cancer.5.u3q2.txt.\n",
      "INFO:global:Processing cancer.5.u3q2.txt.\n",
      "2016-09-25 05:43:45,359 [MainThread  ] [INFO ]  Processing obese.3.u2q2.txt.\n",
      "INFO:global:Processing obese.3.u2q2.txt.\n",
      "2016-09-25 05:43:45,359 [MainThread  ] [INFO ]  Processing cancer.1.u3q2.txt.\n",
      "INFO:global:Processing cancer.1.u3q2.txt.\n",
      "2016-09-25 05:43:45,360 [MainThread  ] [INFO ]  Processing cancer.10.u3q1.txt.\n",
      "INFO:global:Processing cancer.10.u3q1.txt.\n",
      "2016-09-25 05:43:45,361 [MainThread  ] [INFO ]  Processing obese.12.u3q1.txt.\n",
      "INFO:global:Processing obese.12.u3q1.txt.\n",
      "2016-09-25 05:43:45,362 [MainThread  ] [INFO ]  Processing cancer.2.u2q1.txt.\n",
      "INFO:global:Processing cancer.2.u2q1.txt.\n",
      "2016-09-25 05:43:45,362 [MainThread  ] [INFO ]  Processing obese.4.u1q1.txt.\n",
      "INFO:global:Processing obese.4.u1q1.txt.\n",
      "2016-09-25 05:43:45,363 [MainThread  ] [INFO ]  Processing asthma.4.u2q1.txt.\n",
      "INFO:global:Processing asthma.4.u2q1.txt.\n",
      "2016-09-25 05:43:45,364 [MainThread  ] [INFO ]  Processing cancer.4.u2q1.txt.\n",
      "INFO:global:Processing cancer.4.u2q1.txt.\n",
      "2016-09-25 05:43:45,364 [MainThread  ] [INFO ]  Processing obese.3.u1q3.txt.\n",
      "INFO:global:Processing obese.3.u1q3.txt.\n",
      "2016-09-25 05:43:45,365 [MainThread  ] [INFO ]  Processing alz.2.u2q1.txt.\n",
      "INFO:global:Processing alz.2.u2q1.txt.\n",
      "2016-09-25 05:43:45,366 [MainThread  ] [INFO ]  Processing obese.2.u1q3.txt.\n",
      "INFO:global:Processing obese.2.u1q3.txt.\n",
      "2016-09-25 05:43:45,366 [MainThread  ] [INFO ]  Processing cancer.6.u3q3.txt.\n",
      "INFO:global:Processing cancer.6.u3q3.txt.\n",
      "2016-09-25 05:43:45,367 [MainThread  ] [INFO ]  Processing cancer.3.u2q3.txt.\n",
      "INFO:global:Processing cancer.3.u2q3.txt.\n",
      "2016-09-25 05:43:45,368 [MainThread  ] [INFO ]  Processing alz.5.u1q1.txt.\n",
      "INFO:global:Processing alz.5.u1q1.txt.\n",
      "2016-09-25 05:43:45,369 [MainThread  ] [INFO ]  Processing cancer.6.u2q3.txt.\n",
      "INFO:global:Processing cancer.6.u2q3.txt.\n",
      "2016-09-25 05:43:45,369 [MainThread  ] [INFO ]  Processing asthma.2.u3q1.txt.\n",
      "INFO:global:Processing asthma.2.u3q1.txt.\n",
      "2016-09-25 05:43:45,370 [MainThread  ] [INFO ]  Processing asthma.3.u1q2.txt.\n",
      "INFO:global:Processing asthma.3.u1q2.txt.\n",
      "2016-09-25 05:43:45,371 [MainThread  ] [INFO ]  Processing asthma.1.u3q1.txt.\n",
      "INFO:global:Processing asthma.1.u3q1.txt.\n",
      "2016-09-25 05:43:45,371 [MainThread  ] [INFO ]  Processing obese.2.u2q1.txt.\n",
      "INFO:global:Processing obese.2.u2q1.txt.\n",
      "2016-09-25 05:43:45,372 [MainThread  ] [INFO ]  Processing obese.2.u1q2.txt.\n",
      "INFO:global:Processing obese.2.u1q2.txt.\n",
      "2016-09-25 05:43:45,373 [MainThread  ] [INFO ]  Processing obese.2.u1q1.txt.\n",
      "INFO:global:Processing obese.2.u1q1.txt.\n",
      "2016-09-25 05:43:45,373 [MainThread  ] [INFO ]  Processing obese.8.u3q1.txt.\n",
      "INFO:global:Processing obese.8.u3q1.txt.\n",
      "2016-09-25 05:43:45,374 [MainThread  ] [INFO ]  Processing obese.5.u2q3.txt.\n",
      "INFO:global:Processing obese.5.u2q3.txt.\n",
      "2016-09-25 05:43:45,375 [MainThread  ] [INFO ]  Processing obese.2.u3q3.txt.\n",
      "INFO:global:Processing obese.2.u3q3.txt.\n",
      "2016-09-25 05:43:45,375 [MainThread  ] [INFO ]  Processing cancer.6.u3q1.txt.\n",
      "INFO:global:Processing cancer.6.u3q1.txt.\n",
      "2016-09-25 05:43:45,376 [MainThread  ] [INFO ]  Processing obese.4.u2q1.txt.\n",
      "INFO:global:Processing obese.4.u2q1.txt.\n",
      "2016-09-25 05:43:45,377 [MainThread  ] [INFO ]  Processing obese.5.u2q1.txt.\n",
      "INFO:global:Processing obese.5.u2q1.txt.\n",
      "2016-09-25 05:43:45,377 [MainThread  ] [INFO ]  Processing alz.1.u2q2.txt.\n",
      "INFO:global:Processing alz.1.u2q2.txt.\n",
      "2016-09-25 05:43:45,378 [MainThread  ] [INFO ]  Processing asthma.1.u4q3.txt.\n",
      "INFO:global:Processing asthma.1.u4q3.txt.\n",
      "2016-09-25 05:43:45,379 [MainThread  ] [INFO ]  Processing obese.2.u2q3.txt.\n",
      "INFO:global:Processing obese.2.u2q3.txt.\n",
      "2016-09-25 05:43:45,379 [MainThread  ] [INFO ]  Processing cancer.1.u1q3.txt.\n",
      "INFO:global:Processing cancer.1.u1q3.txt.\n",
      "2016-09-25 05:43:45,380 [MainThread  ] [INFO ]  Processing obese.5.u3q2.txt.\n",
      "INFO:global:Processing obese.5.u3q2.txt.\n",
      "2016-09-25 05:43:45,381 [MainThread  ] [INFO ]  Processing alz.2.u1q2.txt.\n",
      "INFO:global:Processing alz.2.u1q2.txt.\n",
      "2016-09-25 05:43:45,382 [MainThread  ] [INFO ]  Processing obese.2.u2q2.txt.\n",
      "INFO:global:Processing obese.2.u2q2.txt.\n",
      "2016-09-25 05:43:45,382 [MainThread  ] [INFO ]  Processing alz.7.u3q1.txt.\n",
      "INFO:global:Processing alz.7.u3q1.txt.\n",
      "2016-09-25 05:43:45,383 [MainThread  ] [INFO ]  Processing cancer.4.u2q3.txt.\n",
      "INFO:global:Processing cancer.4.u2q3.txt.\n",
      "2016-09-25 05:43:45,384 [MainThread  ] [INFO ]  Processing asthma.2.u3q2.txt.\n",
      "INFO:global:Processing asthma.2.u3q2.txt.\n",
      "2016-09-25 05:43:45,384 [MainThread  ] [INFO ]  Processing asthma.1.u3q2.txt.\n",
      "INFO:global:Processing asthma.1.u3q2.txt.\n",
      "2016-09-25 05:43:45,385 [MainThread  ] [INFO ]  Processing asthma.1.u2q1.txt.\n",
      "INFO:global:Processing asthma.1.u2q1.txt.\n",
      "2016-09-25 05:43:45,386 [MainThread  ] [INFO ]  Processing cancer.3.u3q3.txt.\n",
      "INFO:global:Processing cancer.3.u3q3.txt.\n",
      "2016-09-25 05:43:45,386 [MainThread  ] [INFO ]  Processing obese.1.u2q1.txt.\n",
      "INFO:global:Processing obese.1.u2q1.txt.\n",
      "2016-09-25 05:43:45,387 [MainThread  ] [INFO ]  Processing alz.4.u2q2.txt.\n",
      "INFO:global:Processing alz.4.u2q2.txt.\n",
      "2016-09-25 05:43:45,388 [MainThread  ] [INFO ]  Processing cancer.2.u3q2.txt.\n",
      "INFO:global:Processing cancer.2.u3q2.txt.\n",
      "2016-09-25 05:43:45,388 [MainThread  ] [INFO ]  Processing cancer.1.u3q3.txt.\n",
      "INFO:global:Processing cancer.1.u3q3.txt.\n",
      "2016-09-25 05:43:45,389 [MainThread  ] [INFO ]  Processing cancer.2.u1q3.txt.\n",
      "INFO:global:Processing cancer.2.u1q3.txt.\n",
      "2016-09-25 05:43:45,390 [MainThread  ] [INFO ]  Processing cancer.4.u3q2.txt.\n",
      "INFO:global:Processing cancer.4.u3q2.txt.\n",
      "2016-09-25 05:43:45,390 [MainThread  ] [INFO ]  Processing obese.10.u2q1.txt.\n",
      "INFO:global:Processing obese.10.u2q1.txt.\n",
      "2016-09-25 05:43:45,391 [MainThread  ] [INFO ]  Processing obese.5.u3q3.txt.\n",
      "INFO:global:Processing obese.5.u3q3.txt.\n",
      "2016-09-25 05:43:45,392 [MainThread  ] [INFO ]  Processing alz.4.u3q3.txt.\n",
      "INFO:global:Processing alz.4.u3q3.txt.\n",
      "2016-09-25 05:43:45,392 [MainThread  ] [INFO ]  Processing cancer.5.u2q1.txt.\n",
      "INFO:global:Processing cancer.5.u2q1.txt.\n",
      "2016-09-25 05:43:45,393 [MainThread  ] [INFO ]  Processing cancer.4.u3q1.txt.\n",
      "INFO:global:Processing cancer.4.u3q1.txt.\n",
      "2016-09-25 05:43:45,394 [MainThread  ] [INFO ]  Processing alz.1.u2q1.txt.\n",
      "INFO:global:Processing alz.1.u2q1.txt.\n",
      "2016-09-25 05:43:45,395 [MainThread  ] [INFO ]  Processing asthma.4.u1q1.txt.\n",
      "INFO:global:Processing asthma.4.u1q1.txt.\n",
      "2016-09-25 05:43:45,395 [MainThread  ] [INFO ]  Processing obese.7.u2q1.txt.\n",
      "INFO:global:Processing obese.7.u2q1.txt.\n",
      "2016-09-25 05:43:45,396 [MainThread  ] [INFO ]  Processing asthma.5.u3q1.txt.\n",
      "INFO:global:Processing asthma.5.u3q1.txt.\n",
      "2016-09-25 05:43:45,397 [MainThread  ] [INFO ]  Processing cancer.5.u3q3.txt.\n",
      "INFO:global:Processing cancer.5.u3q3.txt.\n",
      "2016-09-25 05:43:45,397 [MainThread  ] [INFO ]  Processing obese.5.u1q3.txt.\n",
      "INFO:global:Processing obese.5.u1q3.txt.\n",
      "2016-09-25 05:43:45,398 [MainThread  ] [INFO ]  Processing asthma.8.u3q1.txt.\n",
      "INFO:global:Processing asthma.8.u3q1.txt.\n",
      "2016-09-25 05:43:45,399 [MainThread  ] [INFO ]  Processing alz.2.u3q2.txt.\n",
      "INFO:global:Processing alz.2.u3q2.txt.\n",
      "2016-09-25 05:43:45,399 [MainThread  ] [INFO ]  Processing asthma.5.u2q2.txt.\n",
      "INFO:global:Processing asthma.5.u2q2.txt.\n",
      "2016-09-25 05:43:45,400 [MainThread  ] [INFO ]  Processing asthma.2.u2q3.txt.\n",
      "INFO:global:Processing asthma.2.u2q3.txt.\n",
      "2016-09-25 05:43:45,401 [MainThread  ] [INFO ]  Processing cancer.3.u1q2.txt.\n",
      "INFO:global:Processing cancer.3.u1q2.txt.\n",
      "2016-09-25 05:43:45,401 [MainThread  ] [INFO ]  Processing asthma.9.u2q1.txt.\n",
      "INFO:global:Processing asthma.9.u2q1.txt.\n",
      "2016-09-25 05:43:45,402 [MainThread  ] [INFO ]  Processing asthma.2.u1q3.txt.\n",
      "INFO:global:Processing asthma.2.u1q3.txt.\n",
      "2016-09-25 05:43:45,403 [MainThread  ] [INFO ]  Processing cancer.6.u2q1.txt.\n",
      "INFO:global:Processing cancer.6.u2q1.txt.\n",
      "2016-09-25 05:43:45,403 [MainThread  ] [INFO ]  Processing obese.7.u1q1.txt.\n",
      "INFO:global:Processing obese.7.u1q1.txt.\n",
      "2016-09-25 05:43:45,404 [MainThread  ] [INFO ]  Processing cancer.3.u3q1.txt.\n",
      "INFO:global:Processing cancer.3.u3q1.txt.\n",
      "2016-09-25 05:43:45,405 [MainThread  ] [INFO ]  Processing asthma.7.u2q1.txt.\n",
      "INFO:global:Processing asthma.7.u2q1.txt.\n",
      "2016-09-25 05:43:45,405 [MainThread  ] [INFO ]  Processing cancer.9.u3q1.txt.\n",
      "INFO:global:Processing cancer.9.u3q1.txt.\n",
      "2016-09-25 05:43:45,406 [MainThread  ] [INFO ]  Processing cancer.5.u2q2.txt.\n",
      "INFO:global:Processing cancer.5.u2q2.txt.\n",
      "2016-09-25 05:43:45,407 [MainThread  ] [INFO ]  Processing asthma.2.u2q2.txt.\n",
      "INFO:global:Processing asthma.2.u2q2.txt.\n",
      "2016-09-25 05:43:45,407 [MainThread  ] [INFO ]  Processing cancer.11.u2q1.txt.\n",
      "INFO:global:Processing cancer.11.u2q1.txt.\n",
      "2016-09-25 05:43:45,408 [MainThread  ] [INFO ]  Processing obese.4.u3q3.txt.\n",
      "INFO:global:Processing obese.4.u3q3.txt.\n",
      "2016-09-25 05:43:45,409 [MainThread  ] [INFO ]  Processing asthma.5.u1q2.txt.\n",
      "INFO:global:Processing asthma.5.u1q2.txt.\n",
      "2016-09-25 05:43:45,410 [MainThread  ] [INFO ]  Processing obese.4.u1q2.txt.\n",
      "INFO:global:Processing obese.4.u1q2.txt.\n",
      "2016-09-25 05:43:45,410 [MainThread  ] [INFO ]  Processing alz.2.u2q3.txt.\n",
      "INFO:global:Processing alz.2.u2q3.txt.\n",
      "2016-09-25 05:43:45,411 [MainThread  ] [INFO ]  Processing cancer.4.u1q2.txt.\n",
      "INFO:global:Processing cancer.4.u1q2.txt.\n",
      "2016-09-25 05:43:45,412 [MainThread  ] [INFO ]  Processing alz.6.u1q1.txt.\n",
      "INFO:global:Processing alz.6.u1q1.txt.\n",
      "2016-09-25 05:43:45,412 [MainThread  ] [INFO ]  Processing asthma.3.u1q1.txt.\n",
      "INFO:global:Processing asthma.3.u1q1.txt.\n",
      "2016-09-25 05:43:45,413 [MainThread  ] [INFO ]  Processing alz.3.u1q1.txt.\n",
      "INFO:global:Processing alz.3.u1q1.txt.\n",
      "2016-09-25 05:43:45,414 [MainThread  ] [INFO ]  Processing alz.2.u3q1.txt.\n",
      "INFO:global:Processing alz.2.u3q1.txt.\n",
      "2016-09-25 05:43:45,414 [MainThread  ] [INFO ]  Processing alz.4.u1q1.txt.\n",
      "INFO:global:Processing alz.4.u1q1.txt.\n",
      "2016-09-25 05:43:45,415 [MainThread  ] [INFO ]  Processing asthma.6.u2q1.txt.\n",
      "INFO:global:Processing asthma.6.u2q1.txt.\n",
      "2016-09-25 05:43:45,416 [MainThread  ] [INFO ]  Processing cancer.6.u2q2.txt.\n",
      "INFO:global:Processing cancer.6.u2q2.txt.\n",
      "2016-09-25 05:43:45,416 [MainThread  ] [INFO ]  Processing obese.1.u3q2.txt.\n",
      "INFO:global:Processing obese.1.u3q2.txt.\n",
      "2016-09-25 05:43:45,417 [MainThread  ] [INFO ]  Processing asthma.1.u2q2.txt.\n",
      "INFO:global:Processing asthma.1.u2q2.txt.\n",
      "2016-09-25 05:43:45,418 [MainThread  ] [INFO ]  Processing obese.8.u2q1.txt.\n",
      "INFO:global:Processing obese.8.u2q1.txt.\n",
      "2016-09-25 05:43:45,418 [MainThread  ] [INFO ]  Processing cancer.5.u2q3.txt.\n",
      "INFO:global:Processing cancer.5.u2q3.txt.\n",
      "2016-09-25 05:43:45,419 [MainThread  ] [INFO ]  Processing cancer.2.u3q3.txt.\n",
      "INFO:global:Processing cancer.2.u3q3.txt.\n",
      "2016-09-25 05:43:45,420 [MainThread  ] [INFO ]  Processing asthma.2.u2q1.txt.\n",
      "INFO:global:Processing asthma.2.u2q1.txt.\n",
      "2016-09-25 05:43:45,420 [MainThread  ] [INFO ]  Processing alz.1.u1q1.txt.\n",
      "INFO:global:Processing alz.1.u1q1.txt.\n",
      "2016-09-25 05:43:45,421 [MainThread  ] [INFO ]  Processing cancer.2.u2q3.txt.\n",
      "INFO:global:Processing cancer.2.u2q3.txt.\n",
      "2016-09-25 05:43:45,422 [MainThread  ] [INFO ]  Processing obese.2.u3q1.txt.\n",
      "INFO:global:Processing obese.2.u3q1.txt.\n",
      "2016-09-25 05:43:45,423 [MainThread  ] [INFO ]  Processing cancer.1.u2q1.txt.\n",
      "INFO:global:Processing cancer.1.u2q1.txt.\n",
      "2016-09-25 05:43:45,423 [MainThread  ] [INFO ]  Processing obese.1.u1q2.txt.\n",
      "INFO:global:Processing obese.1.u1q2.txt.\n",
      "2016-09-25 05:43:45,424 [MainThread  ] [INFO ]  Processing obese.6.u3q3.txt.\n",
      "INFO:global:Processing obese.6.u3q3.txt.\n",
      "2016-09-25 05:43:45,425 [MainThread  ] [INFO ]  Processing obese.6.u1q3.txt.\n",
      "INFO:global:Processing obese.6.u1q3.txt.\n",
      "2016-09-25 05:43:45,425 [MainThread  ] [INFO ]  Processing cancer.4.u1q3.txt.\n",
      "INFO:global:Processing cancer.4.u1q3.txt.\n",
      "2016-09-25 05:43:45,426 [MainThread  ] [INFO ]  Processing cancer.7.u3q1.txt.\n",
      "INFO:global:Processing cancer.7.u3q1.txt.\n",
      "2016-09-25 05:43:45,427 [MainThread  ] [INFO ]  Processing obese.9.u2q1.txt.\n",
      "INFO:global:Processing obese.9.u2q1.txt.\n",
      "2016-09-25 05:43:45,427 [MainThread  ] [INFO ]  Processing cancer.6.u3q2.txt.\n",
      "INFO:global:Processing cancer.6.u3q2.txt.\n",
      "2016-09-25 05:43:45,428 [MainThread  ] [INFO ]  Processing obese.12.u1q1.txt.\n",
      "INFO:global:Processing obese.12.u1q1.txt.\n",
      "2016-09-25 05:43:45,429 [MainThread  ] [INFO ]  Processing asthma.1.u3q3.txt.\n",
      "INFO:global:Processing asthma.1.u3q3.txt.\n",
      "2016-09-25 05:43:45,429 [MainThread  ] [INFO ]  Processing alz.8.u2q1.txt.\n",
      "INFO:global:Processing alz.8.u2q1.txt.\n",
      "2016-09-25 05:43:45,430 [MainThread  ] [INFO ]  Processing obese.12.u2q1.txt.\n",
      "INFO:global:Processing obese.12.u2q1.txt.\n",
      "2016-09-25 05:43:45,431 [MainThread  ] [INFO ]  Processing alz.3.u3q2.txt.\n",
      "INFO:global:Processing alz.3.u3q2.txt.\n",
      "2016-09-25 05:43:45,431 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpdq29DW/model.\n",
      "INFO:global:Saved processed files to /tmp/tmpdq29DW/model.\n",
      "2016-09-25 05:43:45,446 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp8WwxzS/rouge_conf.xml\n",
      "INFO:global:Written ROUGE configuration to /tmp/tmp8WwxzS/rouge_conf.xml\n",
      "2016-09-25 05:43:45,447 [MainThread  ] [INFO ]  Running ROUGE with command /home/ubuntu/ROUGE/RELEASE-1.5.5/ROUGE-1.5.5.pl -e /home/ubuntu/ROUGE/RELEASE-1.5.5/data -n 4 -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0 -a -x -m /tmp/tmp8WwxzS/rouge_conf.xml\n",
      "INFO:global:Running ROUGE with command /home/ubuntu/ROUGE/RELEASE-1.5.5/ROUGE-1.5.5.pl -e /home/ubuntu/ROUGE/RELEASE-1.5.5/data -n 4 -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0 -a -x -m /tmp/tmp8WwxzS/rouge_conf.xml\n"
     ]
    }
   ],
   "source": [
    "output = r.convert_and_evaluate(rouge_args=options)\n",
    "#print(output)\n",
    "output_dict = r.output_to_dict(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.29328 (95%-conf.int. 0.25166 - 0.33412)\n",
      "1 ROUGE-1 Average_P: 0.53727 (95%-conf.int. 0.44934 - 0.62920)\n",
      "1 ROUGE-1 Average_F: 0.30753 (95%-conf.int. 0.27508 - 0.33867)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.10244 (95%-conf.int. 0.09430 - 0.11142)\n",
      "1 ROUGE-2 Average_P: 0.34029 (95%-conf.int. 0.22014 - 0.45677)\n",
      "1 ROUGE-2 Average_F: 0.11803 (95%-conf.int. 0.11066 - 0.12572)\n",
      "---------------------------------------------\n",
      "1 ROUGE-3 Average_R: 0.07776 (95%-conf.int. 0.07225 - 0.08445)\n",
      "1 ROUGE-3 Average_P: 0.30413 (95%-conf.int. 0.18552 - 0.41737)\n",
      "1 ROUGE-3 Average_F: 0.09209 (95%-conf.int. 0.08382 - 0.10050)\n",
      "---------------------------------------------\n",
      "1 ROUGE-4 Average_R: 0.06825 (95%-conf.int. 0.06314 - 0.07454)\n",
      "1 ROUGE-4 Average_P: 0.28168 (95%-conf.int. 0.16932 - 0.38925)\n",
      "1 ROUGE-4 Average_F: 0.08118 (95%-conf.int. 0.07327 - 0.08926)\n",
      "---------------------------------------------\n",
      "1 ROUGE-SU4 Average_R: 0.13029 (95%-conf.int. 0.11632 - 0.14414)\n",
      "1 ROUGE-SU4 Average_P: 0.35971 (95%-conf.int. 0.25142 - 0.46720)\n",
      "1 ROUGE-SU4 Average_F: 0.14374 (95%-conf.int. 0.13589 - 0.15218)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'rouge_su4_precision': 0.35971, u'rouge_3_f_score_cb': 0.08382, u'rouge_3_f_score_ce': 0.1005, u'rouge_1_precision': 0.53727, u'rouge_su4_f_score': 0.14374, u'rouge_3_recall': 0.07776, u'rouge_3_precision_ce': 0.41737, u'rouge_2_precision_ce': 0.45677, u'rouge_2_precision_cb': 0.22014, u'rouge_2_recall': 0.10244, u'rouge_3_precision_cb': 0.18552, u'rouge_4_f_score_ce': 0.08926, u'rouge_2_precision': 0.34029, u'rouge_1_recall_cb': 0.25166, u'rouge_1_recall_ce': 0.33412, u'rouge_4_f_score_cb': 0.07327, u'rouge_2_recall_cb': 0.0943, u'rouge_su4_f_score_ce': 0.15218, u'rouge_su4_f_score_cb': 0.13589, u'rouge_2_recall_ce': 0.11142, u'rouge_4_precision_cb': 0.16932, u'rouge_4_precision_ce': 0.38925, u'rouge_1_f_score': 0.30753, u'rouge_4_recall_ce': 0.07454, u'rouge_su4_precision_ce': 0.4672, u'rouge_1_recall': 0.29328, u'rouge_4_recall_cb': 0.06314, u'rouge_4_recall': 0.06825, u'rouge_3_recall_cb': 0.07225, u'rouge_3_recall_ce': 0.08445, u'rouge_4_precision': 0.28168, u'rouge_4_f_score': 0.08118, u'rouge_3_f_score': 0.09209, u'rouge_2_f_score_cb': 0.11066, u'rouge_3_precision': 0.30413, u'rouge_2_f_score_ce': 0.12572, u'rouge_su4_recall_cb': 0.11632, u'rouge_su4_precision_cb': 0.25142, u'rouge_su4_recall_ce': 0.14414, u'rouge_1_precision_cb': 0.44934, u'rouge_su4_recall': 0.13029, u'rouge_1_precision_ce': 0.6292, u'rouge_2_f_score': 0.11803, u'rouge_1_f_score_ce': 0.33867, u'rouge_1_f_score_cb': 0.27508}\n"
     ]
    }
   ],
   "source": [
    "print(output_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
